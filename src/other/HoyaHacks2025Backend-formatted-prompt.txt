README.md: Not found or error fetching README

Directory Structure:
.cursorrules
.gitignore
calculator_tool.ipynb
[output/]
    _sp-resume.pdf
    sp-resume.aux
    sp-resume.log
    sp-resume.pdf
    sp-resume.tex
    spencer-presley-resume.pdf
pyproject.toml
requirements.txt
[resume_wizard/]
    .DS_Store
    __init__.py
    [__pycache__/]
        __init__.cpython-313.pyc
    [ai/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
        [chains/]
            __init__.py
            [__pycache__/]
                __init__.cpython-313.pyc
            [contact_info/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
            [education/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
            [experience/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
            [languages/]
                __init__.py
                chain.py
                tools.py
            [objective/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
            [projects/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
            [skills/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    chain.cpython-313.pyc
                    tools.cpython-313.pyc
                chain.py
                tools.py
        [tools/]
            __init__.py
            [__pycache__/]
                __init__.cpython-313.pyc
            [res_parser/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    _parser_helper.cpython-313.pyc
                    _res_parsing_tools.cpython-313.pyc
                _parser_helper.py
                _res_parsing_tools.py
    [ai_helpers/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
        [concrete_tools/]
            __init__.py
            [__pycache__/]
                __init__.cpython-313.pyc
            [res_parser/]
                __init__.py
                [__pycache__/]
                    __init__.cpython-313.pyc
                    _parser_helper.cpython-313.pyc
                    _res_parsing_tools.cpython-313.pyc
                _parser_helper.py
                _res_parsing_tools.py
    [api/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
            dependencies.cpython-313.pyc
            routes.cpython-313.pyc
        dependencies.py
        routes.py
        sp-resume.tex
    [converters/]
        __init__.py
        png_to_pdf.py
    [globals/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
        [generic_helpers/]
            __init__.py
            [__pycache__/]
                __init__.cpython-313.pyc
                absolute_paths.cpython-313.pyc
                resume_pdf_dir.cpython-313.pyc
            absolute_paths.py
            resume_pdf_dir.py
    [models/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
        [resume_analysis/]
            __init__.py
            [__pycache__/]
                __init__.cpython-313.pyc
                _support.cpython-313.pyc
                core.cpython-313.pyc
            _support.py
            core.py
    [pdf_parsers/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
            pdf_to_str_parser.cpython-313.pyc
        _test_pdf_parser.py
        pdf_to_str_parser.py
    [resume_tailor/]
        MacTeX.pkg
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
            chain.cpython-313.pyc
            models.cpython-313.pyc
            renderer.cpython-313.pyc
            test_tailor.cpython-313.pyc
            tools.cpython-313.pyc
        chain.py
        jake_resume.aux
        jake_resume.log
        jake_resume.out
        jake_resume.pdf
        models.py
        [output/]
            tailored_resume.pdf.aux
            tailored_resume.pdf.log
            tailored_resume.pdf.out
            tailored_resume.pdf.tex
        renderer.py
        sp-resume.aux
        sp-resume.log
        sp-resume.out
        sp-resume.pdf
        sp-resume.tex
        [template/]
            jake_resume.tex
        test_tailor.py
        tools.py
    [resumes/]
        Kyle_Tranfaglia_Resume.pdf
        Resume-1 (8).pdf
        Resume.pdf
        cole-barbes-resume.pdf
        emily-resume.pdf
        jakes-resume.pdf
        spencer-presley-resume.pdf
    [tests/]
        test_contact_info_chain.py
        test_objective_chain.py
    [vectordb/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
            manager.cpython-313.pyc
            searcher.cpython-313.pyc
        [_vector_db/]
            resume_db.faiss
            resume_db.pkl
        manager.py
        searcher.py
        [vector_db/]
            resume_db.faiss
            resume_db.pkl
    [wizard/]
        __init__.py
        [__pycache__/]
            __init__.cpython-313.pyc
            rezwiz.cpython-313.pyc
        rezwiz.py


calculator_tool.ipynb:
```
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Calculator Tool with Claude\n",
    "In this recipe, we'll demonstrate how to provide Claude with a simple calculator tool that it can use to perform arithmetic operations based on user input. We'll define the calculator tool and show how Claude can interact with it to solve mathematical problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the environment\n",
    "\n",
    "First, let's install the required libraries and set up the Anthropic API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()\n",
    "MODEL_NAME = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the calculator tool\n",
    "We'll define a simple calculator tool that can perform basic arithmetic operations. The tool will take a mathematical expression as input and return the result. \n",
    "\n",
    "Note that we are calling ```eval``` on the outputted expression. This is bad practice and should not be used generally but we are doing it for the purpose of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def calculate(expression):\n",
    "    # Remove any non-digit or non-operator characters from the expression\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        # Evaluate the expression using the built-in eval() function\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"A simple calculator that performs basic arithmetic operations.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The mathematical expression to evaluate (e.g., '2 + 3 * 4').\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we define a calculate function that takes a mathematical expression as input, removes any non-digit or non-operator characters using a regular expression, and then evaluates the expression using the built-in eval() function. If the evaluation is successful, the result is returned as a string. If an error occurs during evaluation, an error message is returned.\n",
    "\n",
    "We then define the calculator tool with an input schema that expects a single expression property of type string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Interact with Claude\n",
    "Now, let's see how Claude can interact with the calculator tool to solve mathematical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"calculator\":\n",
    "        return calculate(tool_input[\"expression\"])\n",
    "\n",
    "def chat_with_claude(user_message):\n",
    "    print(f\"\\n{'='*50}\\nUser Message: {user_message}\\n{'='*50}\")\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nInitial Response:\")\n",
    "    print(f\"Stop Reason: {message.stop_reason}\")\n",
    "    print(f\"Content: {message.content}\")\n",
    "\n",
    "    if message.stop_reason == \"tool_use\":\n",
    "        tool_use = next(block for block in message.content if block.type == \"tool_use\")\n",
    "        tool_name = tool_use.name\n",
    "        tool_input = tool_use.input\n",
    "\n",
    "        print(f\"\\nTool Used: {tool_name}\")\n",
    "        print(f\"Tool Input: {tool_input}\")\n",
    "\n",
    "        tool_result = process_tool_call(tool_name, tool_input)\n",
    "\n",
    "        print(f\"Tool Result: {tool_result}\")\n",
    "\n",
    "        response = client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=4096,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                {\"role\": \"assistant\", \"content\": message.content},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_use.id,\n",
    "                            \"content\": tool_result,\n",
    "                        }\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "            tools=tools,\n",
    "        )\n",
    "    else:\n",
    "        response = message\n",
    "\n",
    "    final_response = next(\n",
    "        (block.text for block in response.content if hasattr(block, \"text\")),\n",
    "        None,\n",
    "    )\n",
    "    print(response.content)\n",
    "    print(f\"\\nFinal Response: {final_response}\")\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Try it out!\n",
    "\n",
    "Let's try giving Claude a few example math questions now that it has access to a calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User Message: What is the result of 1,984,135 * 9,343,116?\n",
      "==================================================\n",
      "\n",
      "Initial Response:\n",
      "Stop Reason: tool_use\n",
      "Content: [ContentBlock(text='<thinking>\\nThe calculator function is the relevant tool to answer this request, since it involves evaluating a mathematical expression.\\n\\nThe required parameter for the calculator function is:\\nexpression: The mathematical expression to evaluate.\\n\\nThe human has directly provided the full expression to evaluate in their request: \"1,984,135 * 9,343,116\". This contains all the information needed for the required expression parameter.\\n\\nSo I have the necessary information to invoke the calculator tool.\\n</thinking>', type='text'), ContentBlockToolUse(id='toolu_01V2mzqp5qkB5QucRFjJUJLD', input={'expression': '1984135 * 9343116'}, name='calculator', type='tool_use')]\n",
      "\n",
      "Tool Used: calculator\n",
      "Tool Input: {'expression': '1984135 * 9343116'}\n",
      "Tool Result: 18538003464660\n",
      "[ContentBlock(text='Therefore, the result of 1,984,135 * 9,343,116 is 18,538,003,464,660.', type='text')]\n",
      "\n",
      "Final Response: Therefore, the result of 1,984,135 * 9,343,116 is 18,538,003,464,660.\n",
      "\n",
      "==================================================\n",
      "User Message: Calculate (12851 - 593) * 301 + 76\n",
      "==================================================\n",
      "\n",
      "Initial Response:\n",
      "Stop Reason: tool_use\n",
      "Content: [ContentBlock(text='<thinking>\\nThe user has provided a mathematical expression to be evaluated: (12851 - 593) * 301 + 76\\nThis can be handled by the calculator tool. Let\\'s check if the required \"expression\" parameter is provided:\\nexpression: \"(12851 - 593) * 301 + 76\" - This is directly provided by the user.\\nSince the required parameter is present, we can proceed with calling the calculator tool.\\n</thinking>', type='text'), ContentBlockToolUse(id='toolu_01Mrrfy9adBzzxvhfZwnyJAe', input={'expression': '(12851 - 593) * 301 + 76'}, name='calculator', type='tool_use')]\n",
      "\n",
      "Tool Used: calculator\n",
      "Tool Input: {'expression': '(12851 - 593) * 301 + 76'}\n",
      "Tool Result: 3689734\n",
      "[ContentBlock(text='So the final result of evaluating the expression (12851 - 593) * 301 + 76 is 3689734.', type='text')]\n",
      "\n",
      "Final Response: So the final result of evaluating the expression (12851 - 593) * 301 + 76 is 3689734.\n",
      "\n",
      "==================================================\n",
      "User Message: What is 15910385 divided by 193053?\n",
      "==================================================\n",
      "\n",
      "Initial Response:\n",
      "Stop Reason: tool_use\n",
      "Content: [ContentBlock(text='<thinking>\\nThe calculator function is the appropriate tool to answer this request, since it can perform basic arithmetic operations like division.\\n\\nThe calculator function requires a single parameter:\\n- expression: The mathematical expression to evaluate\\n\\nIn this case, the user has provided the full expression to evaluate (15910385 divided by 193053). Since all the required information has been provided, we can proceed with calling the calculator function.\\n</thinking>', type='text'), ContentBlockToolUse(id='toolu_01BfnN4LKp7oPRgmRzWeYdBG', input={'expression': '15910385 / 193053'}, name='calculator', type='tool_use')]\n",
      "\n",
      "Tool Used: calculator\n",
      "Tool Input: {'expression': '15910385 / 193053'}\n",
      "Tool Result: 82.41459599177428\n",
      "[ContentBlock(text='So 15910385 divided by 193053 equals 82.41459599177428.', type='text')]\n",
      "\n",
      "Final Response: So 15910385 divided by 193053 equals 82.41459599177428.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'So 15910385 divided by 193053 equals 82.41459599177428.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_claude(\"What is the result of 1,984,135 * 9,343,116?\")\n",
    "chat_with_claude(\"Calculate (12851 - 593) * 301 + 76\")\n",
    "chat_with_claude(\"What is 15910385 divided by 193053?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anthropic Tools SDK",
   "language": "python",
   "name": "ant-tools-sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

```

    resume_wizard/__init__.py:
    ```
"""
Your project's main package.
"""

    ```

        resume_wizard/ai/__init__.py:
        ```
from .chains import (
    create_contact_info_chain, 
    extract_contact_info,
    create_objective_chain,
    extract_objective,
    create_skills_chain,
    extract_skills,
    create_education_chain,
    extract_education
)
from .tools import _ResumeParsingTools, _ResumeParserHelper

__all__ = [
    "create_contact_info_chain", 
    "extract_contact_info",
    "create_objective_chain",
    "extract_objective",
    "create_skills_chain",
    "extract_skills",
    "create_education_chain",
    "extract_education",
    "_ResumeParsingTools", 
    "_ResumeParserHelper"
]
        ```

            resume_wizard/ai/chains/__init__.py:
            ```
from .contact_info.chain import extract_contact_info, create_contact_info_chain
from .objective.chain import extract_objective, create_objective_chain
from .skills.chain import create_skills_chain, extract_skills
from .education.chain import create_education_chain, extract_education
from .experience.chain import create_experience_chain, extract_experience
from .projects.chain import create_projects_chain, extract_projects

__all__ = [
    'extract_contact_info',
    'create_contact_info_chain',
    'extract_objective',
    'create_objective_chain',
    'create_skills_chain',
    'extract_skills',
    'create_education_chain',
    'extract_education',
    'create_experience_chain',
    'extract_experience',
    'create_projects_chain',
    'extract_projects'
]
            ```

                resume_wizard/ai/chains/contact_info/__init__.py:
                ```
from .chain import create_contact_info_chain, extract_contact_info

__all__ = ["create_contact_info_chain", "extract_contact_info"] 
                ```

                resume_wizard/ai/chains/contact_info/chain.py:
                ```
"""Chain for extracting contact information from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_contact_info_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools


CONTACT_INFO_PROMPT = """You are an expert at extracting contact information from resumes.
Your task is to find and extract:
1. Full name
2. Email address
3. Phone number
4. LinkedIn profile URL (if present)
5. GitHub profile URL (if present)

Guidelines:
- Extract information exactly as it appears in the resume
- Do not make assumptions or guess missing information
- If a piece of information is not found, do not include it
- For phone numbers, maintain the exact format found in the resume
- For URLs, include the complete URL as found in the resume

Process:
1. First analyze the text to find all relevant information
2. Use set_contact_info to save name, email, and phone
3. After set_contact_info succeeds, use set_social_links to save LinkedIn and GitHub URLs
4. After all tools complete, give a final summary of what was found and saved

Important: After each tool call completes successfully, continue with the next step. Do not stop until you've completed all steps."""

def create_contact_info_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting contact information from resumes."""
    # Create the tools
    tools = create_contact_info_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=CONTACT_INFO_PROMPT)
    })
    
    return llm_with_tools

def extract_contact_info(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    """Extract contact information from a resume text."""
    print("\n=== Starting Contact Info Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract contact information from this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
                    print(f"Tool Use ID: {block['id']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        
        # Process each tool use
        for tool_use in tool_uses:
            print(f"\nTool Use ID from block: {tool_use['id']}")
            
            print("\n=== Executing Tool ===")
            print(f"Tool Name: {tool_use['name']}")
            print(f"Tool Input: {tool_use['input']}")
            
            # Actually execute the tool
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            
            if tool_name == 'set_contact_info':
                print("Calling set_contact_info...")
                # Ensure phone has a default value of None
                if 'phone' not in tool_args:
                    tool_args['phone'] = None
                result = parser_tools.set_contact_info(**tool_args)
            elif tool_name == 'set_social_links':
                print("Calling set_social_links...")
                result = parser_tools.set_social_links(**tool_args)
            else:
                result = f"Unknown tool: {tool_name}"
                
            print(f"Tool Result: {result}")
            
            # Add tool result to messages
            tool_message = {
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": tool_use['id'],
                        "content": result
                    }
                ]
            }
            messages.append(tool_message)
            
            print("\n=== Added Tool Result ===")
            print(f"Tool Result Message: {tool_message}")
            print(f"Tool Use ID in result: {tool_message['content'][0]['tool_use_id']}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text
                ```

                resume_wizard/ai/chains/contact_info/tools.py:
                ```
"""Tools for extracting contact information from resumes."""
from typing import Optional, Dict, Any

from langchain_anthropic.chat_models import AnthropicTool
from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class ContactInfoInput(BaseModel):
    """Input schema for contact information."""
    name: str = Field(
        description="Full name of the candidate"
    )
    email: str = Field(
        description="Email address"
    )
    phone: Optional[str] = Field(
        None,
        description="Phone number (if available)"
    )

class SocialLinksInput(BaseModel):
    """Input schema for social links."""
    linkedin: Optional[str] = Field(None, description="LinkedIn profile URL found in the resume")
    github: Optional[str] = Field(None, description="GitHub profile URL found in the resume")

def create_contact_info_tools(parser_tools: _ResumeParsingTools) -> list[Dict[str, Any]]:
    """Create Claude-specific tools for contact info extraction.
    
    Args:
        parser_tools: The resume parsing tools instance
        
    Returns:
        list[Dict[str, Any]]: List of Claude-specific tools for contact info extraction
    """
    contact_schema = ContactInfoInput.model_json_schema()
    social_schema = SocialLinksInput.model_json_schema()
    
    # Remove schema elements that Claude doesn't expect
    for schema in [contact_schema, social_schema]:
        if "title" in schema:
            del schema["title"]
        if "$schema" in schema:
            del schema["$schema"]
        if "description" in schema:
            del schema["description"]
        if "required" in schema:
            schema["required"] = [field for field in schema["required"] if field != "phone"]
    
    return [
        {
            "name": "set_contact_info",
            "description": "Save the person's name, email, and phone number found in the resume",
            "input_schema": contact_schema
        },
        {
            "name": "set_social_links",
            "description": "Save the person's LinkedIn and GitHub URLs found in the resume",
            "input_schema": social_schema
        }
    ]
                ```

                resume_wizard/ai/chains/education/__init__.py:
                ```
from .chain import create_education_chain, extract_education

__all__ = ["create_education_chain", "extract_education"] 
                ```

                resume_wizard/ai/chains/education/chain.py:
                ```
"""Chain for extracting education information from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING
import json

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_education_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools


EDUCATION_PROMPT = """You are an expert at extracting education information from resumes.

Your task is to find and extract all education-related information throughout the resume.

Information to Extract:
1. Core Details:
   - Institution name
   - Degree/program
   - Location
   - Dates (start and end/expected)
   - GPA (if provided)

2. Additional Details:
   - Minor fields of study
   - Academic honors/distinctions
   - Relevant coursework
   - Other academic achievements/activities

Guidelines:
- Look for education information in all sections (not just education section)
- Extract details exactly as they appear in the resume
- For each institution found:
  1. First use add_education for core details
  2. Then use add_education_details for additional information
- Handle both completed and ongoing education
- Include all levels of education mentioned (university, college, certifications)
- Pay attention to formatting of dates and GPA
- Don't make assumptions about information not explicitly stated

Process:
1. First analyze the text to identify all educational institutions
2. For each institution:
   a. Extract and save core details using add_education
   b. Extract and save additional details using add_education_details
3. After saving all entries, provide a final summary

Important: After all tool calls complete successfully, provide a final summary of what education information was found and saved."""


def create_education_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting education information from resumes."""
    # Create the tools
    tools = create_education_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=EDUCATION_PROMPT)
    })
    
    return llm_with_tools


def extract_education(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    print("\n=== Starting Education Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract all education information from this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        
        # Process each tool use
        for tool_use in tool_uses:
            print("\n=== Executing Tool ===")
            print(f"Tool Name: {tool_use['name']}")
            print(f"Tool Input: {tool_use['input']}")
            
            # Actually execute the tool
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            
            print(f"\nExecuting tool: {tool_name}")
            print(f"Tool Input: {tool_args}")
            print("Calling " + tool_name + "...")
            
            # Execute the tool
            if tool_name == "add_education":
                result = parser_tools.add_education(**tool_args)
            elif tool_name == "add_education_details":
                result = parser_tools.add_education_details(**tool_args)
            else:
                result = f"Unknown tool: {tool_name}"
                
            print(f"Tool Result: {result}")
            
            # Add tool result to messages
            tool_message = {
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": tool_use['id'],
                        "content": result
                    }
                ]
            }
            messages.append(tool_message)
            
            print("\n=== Added Tool Result ===")
            print(f"Tool Result Message: {tool_message}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/education/tools.py:
                ```
"""Tools for extracting education information from resumes."""
from typing import Optional, Dict, Any, List

from langchain_anthropic.chat_models import AnthropicTool
from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class CoreEducationInput(BaseModel):
    """Input schema for core education details."""
    institution: str = Field(..., description="Name of the educational institution")
    degree: str = Field(..., description="Degree earned or pursued")
    location: Optional[str] = Field(None, description="City and state/country")
    start_date: Optional[str] = Field(None, description="Start date of education")
    end_date: Optional[str] = Field(None, description="End date or expected graduation")
    gpa: Optional[float] = Field(None, description="GPA on 4.0 scale")

class EducationDetailsInput(BaseModel):
    """Input schema for additional education details."""
    institution: str = Field(..., description="Name of the institution (to match existing entry)")
    minors: Optional[List[str]] = Field(None, description="List of minor fields of study")
    honors: Optional[List[str]] = Field(None, description="Academic honors and distinctions")
    relevant_coursework: Optional[List[str]] = Field(None, description="Key relevant courses")
    description: Optional[str] = Field(None, description="Additional details about coursework, achievements, or activities")

def create_education_tools(parser_tools: _ResumeParsingTools) -> list[Dict[str, Any]]:
    """Create Claude-specific tools for education extraction.
    
    Args:
        parser_tools: The resume parsing tools instance
        
    Returns:
        list[Dict[str, Any]]: List of Claude-specific tools for education extraction
    """
    # Get schemas
    core_schema = CoreEducationInput.model_json_schema()
    details_schema = EducationDetailsInput.model_json_schema()
    
    # Remove schema elements that Claude doesn't expect
    for schema in [core_schema, details_schema]:
        if "title" in schema:
            del schema["title"]
        if "$schema" in schema:
            del schema["$schema"]
        if "description" in schema:
            del schema["description"]
    
    return [
        {
            "name": "add_education",
            "description": "Add core education details (institution, degree, dates, etc.)",
            "input_schema": core_schema
        },
        {
            "name": "add_education_details",
            "description": "Add additional education details (minors, honors, coursework, etc.)",
            "input_schema": details_schema
        }
    ] 
                ```

                resume_wizard/ai/chains/experience/__init__.py:
                ```
from .chain import create_experience_chain, extract_experience

__all__ = [
    'create_experience_chain',
    'extract_experience'
] 
                ```

                resume_wizard/ai/chains/experience/chain.py:
                ```
"""Chain for extracting experience information from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING
import json

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_experience_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

EXPERIENCE_PROMPT = """You are an expert at analyzing resumes and extracting professional experience information. Your task is to extract work experience details from the provided resume text.

For each work experience entry you find, you should:

1. First extract and add the core details using add_experience:
   - Position/title
   - Company name
   - Initial description of responsibilities
   - Location (if available)
   - Start and end dates
   - Whether it's a current position
   - Position type (full-time, part-time, internship, etc.)

2. Then add additional details using add_experience_details:
   - Industry sector
   - More detailed description of responsibilities
   - Quantifiable achievements and results
   - Key terms/keywords related to the role
   - Technical tools and technologies used

Extract the experience entries in chronological order (most recent first). Be thorough in capturing all relevant details, especially achievements and technologies used.

Guidelines:
- For the initial add_experience call, include a basic description of the role
- Use add_experience_details to expand on the description and add more specific details
- Extract information exactly as it appears in the resume
- Include all positions mentioned (full-time, part-time, internships)
- Pay attention to dates and position types
- Don't make assumptions about information not explicitly stated

Resume Text:
{resume_text}

Extract the experience information from this resume text. Use the provided tools to add each experience entry and its details."""

def create_experience_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting experience information from resumes."""
    # Create the tools
    tools = create_experience_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=EXPERIENCE_PROMPT)
    })
    
    return llm_with_tools

def extract_experience(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    print("\n=== Starting Experience Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract all experience information from this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        
        # Process each tool use
        for tool_use in tool_uses:
            print("\n=== Executing Tool ===")
            print(f"Tool Name: {tool_use['name']}")
            print(f"Tool Input: {tool_use['input']}")
            
            # Actually execute the tool
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            
            print(f"\nExecuting tool: {tool_name}")
            print(f"Tool Input: {tool_args}")
            print("Calling " + tool_name + "...")
            
            # Execute the tool
            if tool_name == "add_experience":
                result = parser_tools.add_experience(**tool_args)
            elif tool_name == "add_experience_details":
                result = parser_tools.add_experience_details(**tool_args)
            else:
                result = f"Unknown tool: {tool_name}"
                
            print(f"Tool Result: {result}")
            
            # Add tool result to messages
            tool_message = {
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": tool_use['id'],
                        "content": result
                    }
                ]
            }
            messages.append(tool_message)
            
            print("\n=== Added Tool Result ===")
            print(f"Tool Result Message: {tool_message}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/experience/tools.py:
                ```
"""Tools for extracting experience information from resumes."""
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field

class CoreExperienceInput(BaseModel):
    """Input schema for core experience details."""
    position: str = Field(
        description="Job title or role"
    )
    company: str = Field(
        description="Name of the employer or organization"
    )
    description: str = Field(
        description="Initial description of responsibilities and achievements"
    )
    location: Optional[str] = Field(
        None,
        description="City and state/country of the workplace"
    )
    start_date: Optional[str] = Field(
        None,
        description="Start date of employment"
    )
    end_date: Optional[str] = Field(
        None,
        description="End date of employment"
    )
    ongoing: Optional[bool] = Field(
        None,
        description="Whether this is a current position"
    )

class ExperienceDetailsInput(BaseModel):
    """Input schema for additional experience details."""
    position: str = Field(
        description="Position title (to match existing entry)"
    )
    company: str = Field(
        description="Company name (to match existing entry)"
    )
    type: Optional[str] = Field(
        None,
        description="Type of position (full-time, part-time, internship, etc.)"
    )
    industry: Optional[str] = Field(
        None,
        description="Industry sector of the position"
    )
    description: Optional[str] = Field(
        None,
        description="Detailed description of responsibilities and achievements"
    )
    achievements: Optional[List[str]] = Field(
        None,
        description="Quantifiable results and key accomplishments"
    )
    keywords: Optional[List[str]] = Field(
        None,
        description="Key terms related to job responsibilities and skills"
    )
    technologies: Optional[List[str]] = Field(
        None,
        description="Technical tools and technologies used in the role"
    )

def create_experience_tools(tools: Any) -> List[Dict[str, Any]]:
    """Create tools for extracting experience information.
    
    Args:
        tools: The tools instance containing experience-related methods
        
    Returns:
        List[Dict[str, Any]]: List of tool configurations for Claude
    """
    # Remove fields Claude doesn't expect
    core_schema = CoreExperienceInput.model_json_schema()
    del core_schema["title"]
    del core_schema["description"]
    
    details_schema = ExperienceDetailsInput.model_json_schema()
    del details_schema["title"]
    del details_schema["description"]
    
    return [
        {
            "type": "function",
            "function": {
                "name": "add_experience",
                "description": "Add a new experience entry with core details like position, company, dates, etc.",
                "parameters": core_schema
            }
        },
        {
            "type": "function",
            "function": {
                "name": "add_experience_details",
                "description": "Add additional details to an existing experience entry like type, industry, description, achievements, etc.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "position": {
                            "type": "string",
                            "description": "Position/title of the experience entry to update"
                        },
                        "company": {
                            "type": "string",
                            "description": "Company name of the experience entry to update"
                        },
                        **details_schema["properties"]
                    },
                    "required": ["position", "company"]
                }
            }
        }
    ] 
                ```

                resume_wizard/ai/chains/languages/__init__.py:
                ```
from .chain import create_languages_chain, extract_languages

__all__ = ["create_languages_chain", "extract_languages"] 
                ```

                resume_wizard/ai/chains/languages/chain.py:
                ```
"""Chain for extracting all skills from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_skills_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools


SKILLS_PROMPT = """You are an expert at identifying and categorizing technical and professional skills from resumes.

Your task is to find and extract all skills mentioned throughout the resume, categorizing them appropriately.

Categories to identify:
1. Programming Languages (Python, Java, etc.)
2. Frameworks (React, Django, etc.)
3. Development Tools (Git, Docker, etc.)
4. Databases (PostgreSQL, MongoDB, etc.)
5. Libraries (NumPy, Pandas, etc.)
6. Cloud Platforms (AWS, Azure, etc.)
7. Methodologies (Agile, Scrum, etc.)
8. Soft Skills (Leadership, Communication, etc.)
9. Other Technical Skills (that don't fit above categories)

Guidelines:
- Look for skills in all sections (skills, projects, experience, etc.)
- Categorize each skill appropriately using the specific tool for that category
- Extract skills exactly as they appear in the resume
- If a skill appears multiple times, only include it once
- Do not make assumptions or add skills not explicitly mentioned
- Distinguish between similar items (e.g., Python is a language, Django is a framework)

Process:
1. First analyze the entire text to identify all skills
2. Use the appropriate tool for each category:
   - add_programming_languages for languages
   - add_technical_skills with "frameworks" for frameworks
   - add_technical_skills with "dev_tools" for development tools
   - add_technical_skills with "databases" for databases
   - add_technical_skills with "libraries" for libraries
   - add_technical_skills with "cloud_platforms" for cloud platforms
   - add_technical_skills with "methodologies" for methodologies
   - add_soft_skills for soft skills
   - add_technical_skills with "other" for other technical skills
3. After saving all categories, provide a final summary of what was found

Important: After all tool calls complete successfully, provide a final summary of what skills were found and saved in each category."""


def create_skills_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting all skills from resumes."""
    # Create the tools
    tools = create_skills_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=SKILLS_PROMPT)
    })
    
    return llm_with_tools


def extract_skills(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    """Extract all skills from resume text."""
    print("\n=== Starting Skills Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract and categorize all skills mentioned in this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get the tool use block
        tool_use = next(block for block in response.content if block.get('type') == "tool_use")
        
        print("\n=== Executing Tool ===")
        print(f"Tool Name: {tool_use['name']}")
        print(f"Tool Input: {tool_use['input']}")
        
        # Actually execute the tool
        tool_name = tool_use['name']
        tool_args = tool_use['input']
        
        if tool_name == 'add_programming_languages':
            print("Calling add_programming_languages...")
            result = parser_tools.add_programming_languages(**tool_args)
        elif tool_name == 'add_technical_skills':
            print("Calling add_technical_skills...")
            result = parser_tools.add_technical_skills(**tool_args)
        elif tool_name == 'add_soft_skills':
            print("Calling add_soft_skills...")
            result = parser_tools.add_soft_skills(**tool_args)
        else:
            result = f"Unknown tool: {tool_name}"
            
        print(f"Tool Result: {result}")
        
        # Add tool result to messages
        tool_message = {
            "role": "user",
            "content": [
                {
                    "type": "tool_result",
                    "tool_use_id": tool_use['id'],
                    "content": result
                }
            ]
        }
        messages.append(tool_message)
        
        print("\n=== Added Tool Result ===")
        print(f"Tool Result Message: {tool_message}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/languages/tools.py:
                ```
"""Tools for extracting all skills from resumes."""
from typing import Optional, Dict, Any, List

from langchain_anthropic.chat_models import AnthropicTool
from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class LanguagesInput(BaseModel):
    """Input schema for languages extraction."""
    languages: List[str] = Field(..., description="List of programming languages found in the resume")

class TechnicalSkillsInput(BaseModel):
    """Input schema for technical skills extraction."""
    skill_type: str = Field(..., description="Type of skills (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies, other)")
    skills: List[str] = Field(..., description="List of skills in this category")

class SoftSkillsInput(BaseModel):
    """Input schema for soft skills extraction."""
    skills: List[str] = Field(..., description="List of soft skills found in the resume")

def create_skills_tools(parser_tools: _ResumeParsingTools) -> list[Dict[str, Any]]:
    """Create Claude-specific tools for skills extraction.
    
    Args:
        parser_tools: The resume parsing tools instance
        
    Returns:
        list[Dict[str, Any]]: List of Claude-specific tools for skills extraction
    """
    # Get schemas
    languages_schema = LanguagesInput.model_json_schema()
    technical_skills_schema = TechnicalSkillsInput.model_json_schema()
    soft_skills_schema = SoftSkillsInput.model_json_schema()
    
    # Remove schema elements that Claude doesn't expect
    for schema in [languages_schema, technical_skills_schema, soft_skills_schema]:
        if "title" in schema:
            del schema["title"]
        if "$schema" in schema:
            del schema["$schema"]
        if "description" in schema:
            del schema["description"]
    
    return [
        {
            "name": "add_programming_languages",
            "description": "Save programming languages found in the resume",
            "input_schema": languages_schema
        },
        {
            "name": "add_technical_skills",
            "description": "Save technical skills of a specific type (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies, other)",
            "input_schema": technical_skills_schema
        },
        {
            "name": "add_soft_skills",
            "description": "Save soft skills found in the resume",
            "input_schema": soft_skills_schema
        }
    ] 
                ```

                resume_wizard/ai/chains/objective/__init__.py:
                ```
from .chain import create_objective_chain, extract_objective

__all__ = ["create_objective_chain", "extract_objective"] 
                ```

                resume_wizard/ai/chains/objective/chain.py:
                ```
"""Chain for extracting career objective from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_objective_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools


OBJECTIVE_PROMPT = """You are an expert at extracting career objectives and professional summaries from resumes.

Your task is to find and extract the career objective or professional summary section from the resume.

Guidelines:
- Look for sections titled "Objective", "Summary", "Professional Summary", etc.
- Extract the complete text of the objective/summary
- Maintain the original wording and formatting
- If multiple sections exist, combine them appropriately
- If no clear objective/summary exists, do not make one up

Process:
1. First analyze the text to find any objective or summary sections
2. Use set_objective to save the extracted text
3. After saving, provide a final summary of what was found

Important: After the tool call completes successfully, provide a final summary of what was extracted and saved."""


def create_objective_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting career objective from resumes."""
    # Create the tools
    tools = create_objective_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=OBJECTIVE_PROMPT)
    })
    
    return llm_with_tools


def extract_objective(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    """Extract career objective from resume text."""
    print("\n=== Starting Objective Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract the career objective or professional summary from this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get the tool use block
        tool_use = next(block for block in response.content if block.get('type') == "tool_use")
        
        print("\n=== Executing Tool ===")
        print(f"Tool Name: {tool_use['name']}")
        print(f"Tool Input: {tool_use['input']}")
        
        # Actually execute the tool
        tool_name = tool_use['name']
        tool_args = tool_use['input']
        
        if tool_name == 'set_objective':
            print("Calling set_objective...")
            result = parser_tools.set_objective(**tool_args)
        else:
            result = f"Unknown tool: {tool_name}"
            
        print(f"Tool Result: {result}")
        
        # Add tool result to messages
        tool_message = {
            "role": "user",
            "content": [
                {
                    "type": "tool_result",
                    "tool_use_id": tool_use['id'],
                    "content": result
                }
            ]
        }
        messages.append(tool_message)
        
        print("\n=== Added Tool Result ===")
        print(f"Tool Result Message: {tool_message}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/objective/tools.py:
                ```
"""Tools for extracting career objective from resumes."""
from typing import Optional, Dict, Any

from langchain_anthropic.chat_models import AnthropicTool
from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class ObjectiveInput(BaseModel):
    """Input schema for objective extraction."""
    objective: str = Field(..., description="Career objective or professional summary text found in the resume")

def create_objective_tools(parser_tools: _ResumeParsingTools) -> list[Dict[str, Any]]:
    """Create Claude-specific tools for objective extraction.
    
    Args:
        parser_tools: The resume parsing tools instance
        
    Returns:
        list[Dict[str, Any]]: List of Claude-specific tools for objective extraction
    """
    objective_schema = ObjectiveInput.model_json_schema()
    
    # Remove schema elements that Claude doesn't expect
    if "title" in objective_schema:
        del objective_schema["title"]
    if "$schema" in objective_schema:
        del objective_schema["$schema"]
    if "description" in objective_schema:
        del objective_schema["description"]
    
    return [
        {
            "name": "set_objective",
            "description": "Save the career objective or professional summary found in the resume",
            "input_schema": objective_schema
        }
    ] 
                ```

                resume_wizard/ai/chains/projects/__init__.py:
                ```
from .chain import create_projects_chain, extract_projects

__all__ = ["create_projects_chain", "extract_projects"] 
                ```

                resume_wizard/ai/chains/projects/chain.py:
                ```
"""Chain for extracting project information from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING
import json

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_project_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

PROJECTS_PROMPT = """You are an expert at analyzing resumes and extracting project information. Your task is to extract details about all projects mentioned in the resume.

For each project you find, you should:

1. First extract and add the core details using add_project:
   - Project name/title
   - Description and impact
   - Project URL/repository link (if available)
   - Timeframe/duration
   - Individual's role/contribution
   - Team size (if mentioned)
   - Project status (completed, ongoing, etc.)

2. Then add additional details using add_project_details:
   - Technologies used (programming languages, frameworks, tools)
   - Keywords describing features and outcomes

Guidelines:
- Look for projects in all sections (not just a projects section)
- Include both personal and academic projects
- Extract information exactly as it appears in the resume
- For each project:
  1. First use add_project for core details
  2. Then use add_project_details for technologies and keywords
- Pay attention to:
  - Project scope and impact
  - Technical implementation details
  - Role and responsibilities
  - Measurable outcomes
- Don't make assumptions about information not explicitly stated

Process:
1. First analyze the text to identify all projects
2. For each project found:
   a. Extract and save core details using add_project
   b. Extract and save additional details using add_project_details
3. After saving all entries, provide a final summary

Important: After all tool calls complete successfully, provide a final summary of what projects were found and saved."""

def create_projects_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting project information from resumes."""
    # Create the tools
    tools = create_project_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=PROJECTS_PROMPT)
    })
    
    return llm_with_tools

def extract_projects(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    """Extract project information from resume text."""
    print("\n=== Starting Projects Extraction ===")
    
    messages = [
        HumanMessage(content=f"Please extract all project information from this resume:\n\n{resume_text}")
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg.__class__.__name__}: {msg.content[:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append(AIMessage(content=response.content))
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg.__class__.__name__}: {str(msg.content)[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        
        # Process each tool use
        for tool_use in tool_uses:
            print("\n=== Executing Tool ===")
            print(f"Tool Name: {tool_use['name']}")
            print(f"Tool Input: {tool_use['input']}")
            
            # Actually execute the tool
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            
            print(f"\nExecuting tool: {tool_name}")
            print(f"Tool Input: {tool_args}")
            print("Calling " + tool_name + "...")
            
            # Execute the tool
            if tool_name == "add_project":
                result = parser_tools.add_project(**tool_args)
            elif tool_name == "add_project_details":
                result = parser_tools.add_project_details(**tool_args)
            else:
                result = f"Unknown tool: {tool_name}"
                
            print(f"Tool Result: {result}")
            
            # Add tool result to messages
            messages.append(HumanMessage(content=[{
                "type": "tool_result",
                "tool_use_id": tool_use['id'],
                "content": result
            }]))
            
            print("\n=== Added Tool Result ===")
            print(f"Tool Result Message: {messages[-1]}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/projects/tools.py:
                ```
"""Tools for extracting project information from resumes."""
from typing import List, Dict, Any, Optional

from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class CoreProjectInput(BaseModel):
    """Input schema for core project details."""
    name: str = Field(
        description="Title of the project"
    )
    description: str = Field(
        description="Detailed explanation of the project and its impact"
    )
    url: Optional[str] = Field(
        None,
        description="Link to project repository or demo"
    )
    timeframe: Optional[str] = Field(
        None,
        description="Duration or completion date of the project"
    )

class ProjectDetailsInput(BaseModel):
    """Input schema for additional project details."""
    name: str = Field(
        description="Title of the project to update"
    )
    role: Optional[str] = Field(
        None,
        description="Individual's role or contribution to the project"
    )
    team_size: Optional[int] = Field(
        None,
        description="Number of team members involved"
    )
    status: Optional[str] = Field(
        None,
        description="Current status of the project (completed, ongoing, etc.)"
    )
    technologies: Optional[List[str]] = Field(
        None,
        description="Technical tools and technologies used in the project"
    )
    keywords: Optional[List[str]] = Field(
        None,
        description="Key terms describing project features and outcomes"
    )

def create_project_tools(tools: Any) -> List[Dict[str, Any]]:
    """Create tools for extracting project information.
    
    Args:
        tools: The tools instance containing project-related methods
        
    Returns:
        List[Dict[str, Any]]: List of tool configurations for Claude
    """
    # Remove fields Claude doesn't expect
    core_schema = CoreProjectInput.model_json_schema()
    del core_schema["title"]
    del core_schema["description"]
    
    details_schema = ProjectDetailsInput.model_json_schema()
    del details_schema["title"]
    del details_schema["description"]
    
    return [
        {
            "type": "function",
            "function": {
                "name": "add_project",
                "description": "Add a new project entry with core details like name, description, URL, etc.",
                "parameters": core_schema
            }
        },
        {
            "type": "function",
            "function": {
                "name": "add_project_details",
                "description": "Add additional details to an existing project entry like technologies and keywords",
                "parameters": details_schema
            }
        }
    ] 
                ```

                resume_wizard/ai/chains/skills/__init__.py:
                ```
from .chain import create_skills_chain, extract_skills

__all__ = ["create_skills_chain", "extract_skills"] 
                ```

                resume_wizard/ai/chains/skills/chain.py:
                ```
"""Chain for extracting all skills from resumes."""
from __future__ import annotations

from typing import Any, TYPE_CHECKING
import json

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnablePassthrough

from .tools import create_skills_tools
from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools


SKILLS_PROMPT = """You are an expert at identifying and categorizing technical and professional skills from resumes.

Your task is to find and extract all skills mentioned throughout the resume, categorizing them appropriately.

Categories to identify:
1. Programming Languages (Python, Java, etc.)
2. Frameworks (React, Django, etc.)
3. Development Tools (Git, Docker, etc.)
4. Databases (PostgreSQL, MongoDB, etc.)
5. Libraries (NumPy, Pandas, etc.)
6. Cloud Platforms (AWS, Azure, etc.)
7. Methodologies (Agile, Scrum, etc.)
8. Soft Skills (Leadership, Communication, etc.)
9. Other Technical Skills (that don't fit above categories)

Guidelines:
- Look for skills in all sections (skills, projects, experience, etc.)
- Categorize each skill appropriately using the specific tool for that category
- Extract skills exactly as they appear in the resume
- If a skill appears multiple times, only include it once
- Do not make assumptions or add skills not explicitly mentioned
- Distinguish between similar items (e.g., Python is a language, Django is a framework)

Process:
1. First analyze the entire text to identify all skills
2. Use the appropriate tool for each category:
   - add_programming_languages for languages
   - add_technical_skills with "frameworks" for frameworks
   - add_technical_skills with "dev_tools" for development tools
   - add_technical_skills with "databases" for databases
   - add_technical_skills with "libraries" for libraries
   - add_technical_skills with "cloud_platforms" for cloud platforms
   - add_technical_skills with "methodologies" for methodologies
   - add_soft_skills for soft skills
   - add_technical_skills with "other" for other technical skills
3. After saving all categories, provide a final summary of what was found

Important: After all tool calls complete successfully, provide a final summary of what skills were found and saved in each category."""


def create_skills_chain(
    api_key: str,
    parser_tools: _ResumeParsingTools,
) -> RunnablePassthrough:
    """Create a chain for extracting all skills from resumes."""
    # Create the tools
    tools = create_skills_tools(parser_tools)
    
    # Initialize Claude without tools
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096,
    )
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Add system message
    llm_with_tools = llm_with_tools.with_config({
        "system_message": SystemMessage(content=SKILLS_PROMPT)
    })
    
    return llm_with_tools


def extract_skills(
    chain: RunnablePassthrough,
    resume_text: str,
    parser_tools: _ResumeParsingTools
) -> str:
    print("\n=== Starting Skills Extraction ===")
    
    messages = [
        {"role": "user", "content": f"Please extract all skills from this resume:\n\n{resume_text}"}
    ]
    
    print("\n=== Initial Message History ===")
    for msg in messages:
        print(f"{msg['role'].upper()}: {msg['content'][:100]}...")
    
    while True:
        print("\n=== Getting Next Response ===")
        response = chain.invoke(messages)
        
        print("\n=== Response Details ===")
        print(f"Stop Reason: {response.response_metadata.get('stop_reason')}")
        print(f"Content Type: {type(response.content)}")
        if isinstance(response.content, list):
            for block in response.content:
                print(f"Block Type: {block.get('type')}")
                if block.get('type') == 'text':
                    print(f"Text: {block['text']}")
                elif block.get('type') == 'tool_use':
                    print(f"Tool: {block['name']}")
                    print(f"Input: {block['input']}")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        print("\n=== Current Message History ===")
        for msg in messages:
            print(f"{msg['role'].upper()}: {str(msg['content'])[:100]}...")
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("\n=== Conversation Complete ===")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        
        # Process each tool use
        for tool_use in tool_uses:
            print("\n=== Executing Tool ===")
            print(f"Tool Name: {tool_use['name']}")
            print(f"Tool Input: {tool_use['input']}")
            
            # Actually execute the tool
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            
            print(f"\nExecuting tool: {tool_name}")
            print(f"Tool Input: {tool_args}")
            print("Calling " + tool_name + "...")
            
            # Execute the tool
            if tool_name == "add_programming_languages":
                result = parser_tools.add_programming_languages(**tool_args)
            elif tool_name == "add_technical_skills":
                result = parser_tools.add_technical_skills(**tool_args)
            elif tool_name == "add_soft_skills":
                result = parser_tools.add_soft_skills(**tool_args)
            else:
                result = f"Unknown tool: {tool_name}"
                
            print(f"Tool Result: {result}")
            
            # Add tool result to messages
            tool_message = {
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": tool_use['id'],
                        "content": result
                    }
                ]
            }
            messages.append(tool_message)
            
            print("\n=== Added Tool Result ===")
            print(f"Tool Result Message: {tool_message}")
    
    print("\n=== Final Response ===")
    if isinstance(response.content, str):
        print(f"String Content: {response.content}")
        return response.content
    else:
        final_text = next(
            (block['text'] for block in response.content if block.get('type') == 'text'),
            None
        )
        print(f"Block Content: {final_text}")
        return final_text 
                ```

                resume_wizard/ai/chains/skills/tools.py:
                ```
"""Tools for extracting all skills from resumes."""
from typing import Optional, Dict, Any, List

from langchain_anthropic.chat_models import AnthropicTool
from pydantic import BaseModel, Field

from resume_wizard.ai_helpers.concrete_tools.res_parser import _ResumeParsingTools

class LanguagesInput(BaseModel):
    """Input schema for languages extraction."""
    languages: List[str] = Field(..., description="List of programming languages found in the resume")

class TechnicalSkillsInput(BaseModel):
    """Input schema for technical skills extraction."""
    skill_type: str = Field(..., description="Type of skills (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies, other)")
    skills: List[str] = Field(..., description="List of skills in this category")

class SoftSkillsInput(BaseModel):
    """Input schema for soft skills extraction."""
    skills: List[str] = Field(..., description="List of soft skills found in the resume")

def create_skills_tools(parser_tools: _ResumeParsingTools) -> list[Dict[str, Any]]:
    """Create Claude-specific tools for skills extraction.
    
    Args:
        parser_tools: The resume parsing tools instance
        
    Returns:
        list[Dict[str, Any]]: List of Claude-specific tools for skills extraction
    """
    # Get schemas
    languages_schema = LanguagesInput.model_json_schema()
    technical_skills_schema = TechnicalSkillsInput.model_json_schema()
    soft_skills_schema = SoftSkillsInput.model_json_schema()
    
    # Remove schema elements that Claude doesn't expect
    for schema in [languages_schema, technical_skills_schema, soft_skills_schema]:
        if "title" in schema:
            del schema["title"]
        if "$schema" in schema:
            del schema["$schema"]
        if "description" in schema:
            del schema["description"]
    
    return [
        {
            "name": "add_programming_languages",
            "description": "Save programming languages found in the resume",
            "input_schema": languages_schema
        },
        {
            "name": "add_technical_skills",
            "description": "Save technical skills of a specific type (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies, other)",
            "input_schema": technical_skills_schema
        },
        {
            "name": "add_soft_skills",
            "description": "Save soft skills found in the resume",
            "input_schema": soft_skills_schema
        }
    ] 
                ```

            resume_wizard/ai/tools/__init__.py:
            ```
from .res_parser import _ResumeParsingTools, _ResumeParserHelper

__all__ = ["_ResumeParsingTools", "_ResumeParserHelper"]
            ```

                resume_wizard/ai/tools/res_parser/__init__.py:
                ```
from ._res_parsing_tools import _ResumeParsingTools
from ._parser_helper import _ResumeParserHelper

__all__ = ["_ResumeParsingTools", "_ResumeParserHelper"]
                ```

                resume_wizard/ai/tools/res_parser/_parser_helper.py:
                ```
from typing import Type, Dict, List, Any, Optional
from pydantic import BaseModel
import random

from resume_wizard.models.resume_analysis._support import (
    _EducationSchema,
    _ExperienceSchema,
    _ProjectSchema,
    _SkillsSchema
)
from resume_wizard.models.resume_analysis.core import ResumeAnalysisSchema

class _ResumeParserHelper(BaseModel):
    """Helper class for managing resume data during parsing."""
    
    # Basic tracking
    user_int: int = 0
    
    # Storage for resume sections
    contact_info: Dict[str, str] = {}
    social_links: Dict[str, Optional[str]] = {"linkedin": None, "github": None}
    objective: Optional[str] = None
    
    # Complex sections
    education_entries: List[Dict[str, Any]] = []
    experience_entries: List[Dict[str, Any]] = []
    project_entries: List[Dict[str, Any]] = []
    skills: Dict[str, List[str]] = {
        "languages": [],
        "frameworks": [],
        "dev_tools": [],
        "databases": [],
        "libraries": [],
        "cloud_platforms": [],
        "methodologies": [],
        "soft_skills": [],
        "other": []
    }
    
    def generate_random_name(self) -> str:
        """Generate a random name.
        
        Returns:
            str: A random name
        """
        name = f"person_{self.user_int}"
        self._increment_user_int()
        return name
    
    def generate_random_email(self) -> str:
        """Generate a random email address.
        
        Returns:
            str: A random email address
        """
        return f"person_{random.randint(1000, 9999)}@example.com"
    
    def generate_random_phone(self) -> str:
        """Generate a random phone number.
        
        Returns:
            str: A random phone number
        """
        return f"{random.randint(1000000000, 9999999999)}"
    
    def add_education(self, entry: Dict[str, Any]) -> None:
        """Add a new education entry."""
        self.education_entries.append(entry)
        
    def add_education_details(self, institution: str, details: Dict[str, Any]) -> None:
        """Add details to an existing education entry."""
        for entry in self.education_entries:
            if entry["institution"] == institution:
                entry.update(details)
                break
                
    def add_experience(self, entry: Dict[str, Any]) -> None:
        """Add a new experience entry."""
        self.experience_entries.append(entry)
        
    def add_experience_details(
        self, 
        position: str, 
        company: str, 
        details: Dict[str, Any]
    ) -> None:
        """Add details to an existing experience entry."""
        for entry in self.experience_entries:
            if entry["position"] == position and entry["company"] == company:
                entry.update(details)
                break
                
    def add_project(self, entry: Dict[str, Any]) -> None:
        """Add a new project entry."""
        self.project_entries.append(entry)
        
    def add_project_details(self, name: str, details: Dict[str, Any]) -> None:
        """Add details to an existing project entry."""
        for entry in self.project_entries:
            if entry["name"] == name:
                entry.update(details)
                break
                
    def add_languages(self, languages: List[str]) -> None:
        """Add programming languages."""
        self.skills["languages"].extend(languages)
        
    def add_skills(self, skill_type: str, skills: List[str]) -> None:
        """Add skills of a specific type."""
        if skill_type in self.skills:
            self.skills[skill_type].extend(skills)
            
    def add_soft_skills(self, skills: List[str]) -> None:
        """Add soft skills."""
        self.skills["soft_skills"].extend(skills)
    
    def build_resume_schema(self) -> ResumeAnalysisSchema:
        """Construct the final ResumeAnalysisSchema from collected data.
        
        Returns:
            ResumeAnalysisSchema: The complete resume schema
        """
        # Convert education entries to schema objects
        education_schemas = [
            _EducationSchema(**entry)
            for entry in self.education_entries
        ]
        
        # Convert experience entries to schema objects
        experience_schemas = [
            _ExperienceSchema(**entry)
            for entry in self.experience_entries
        ]
        
        # Convert project entries to schema objects
        project_schemas = [
            _ProjectSchema(**entry)
            for entry in self.project_entries
        ]
        
        # Build skills schema
        skills_schema = _SkillsSchema(
            languages=self.skills["languages"],
            frameworks=self.skills["frameworks"],
            dev_tools=self.skills["dev_tools"],
            databases=self.skills["databases"],
            libraries=self.skills["libraries"],
            cloud_platforms=self.skills["cloud_platforms"],
            methodologies=self.skills["methodologies"],
            soft_skills=self.skills["soft_skills"],
            other=self.skills["other"]
        )
        
        # Construct and return the full schema
        return ResumeAnalysisSchema(
            name=self.contact_info.get("name"),
            email=self.contact_info.get("email"),
            phone=self.contact_info.get("phone"),
            linkedin=self.social_links.get("linkedin"),
            github=self.social_links.get("github"),
            objective=self.objective,
            education=education_schemas,
            experience=experience_schemas,
            skills=skills_schema,
            projects=project_schemas,
            languages=self.skills["languages"]  # Languages appear both in skills and at top level
        )
    
    @classmethod
    def _increment_user_int(cls: Type['_ResumeParserHelper']) -> None:
        """Increment the user_int."""
        cls.user_int += 1

                ```

                resume_wizard/ai/tools/res_parser/_res_parsing_tools.py:
                ```
"""Tools for parsing resumes."""
from __future__ import annotations

from typing import TYPE_CHECKING, List, Dict, Any, Optional

from pydantic import BaseModel, Field

if TYPE_CHECKING:
    from ._parser_helper import _ResumeParserHelper
    from resume_wizard.models.resume_analysis.core import ResumeAnalysisSchema

class _ResumeParsingTools(BaseModel):
    """A class housing helper methods for parsing resumes.
    
    The class is a collections of methods to be made available to an LLM to act as 'tools' to populate the `ResumeAnalysisSchema` model during parsing of a resume.
    """
    parser_helper: _ResumeParserHelper

    def set_contact_info(
        self,
        name: str | None,
        email: str | None,
        phone: str | None,
    ) -> str:
        """Set basic contact information for the resume.
        
        Args:
            name (str | None): The name of the person on the resume.
            email (str | None): The email address of the person on the resume.
            phone (str | None): The phone number of the person on the resume.
            
        Returns:
            str: Confirmation message of what was set
        """
        self.parser_helper.contact_info = {
            "name": name or self.parser_helper.generate_random_name(),
            "email": email or self.parser_helper.generate_random_email(),
            "phone": phone or self.parser_helper.generate_random_phone(),
        }
        return f"Set contact info for {name}"

    def set_social_links(
        self,
        linkedin: str | None = None,
        github: str | None = None,
    ) -> str:
        """Set social media links for the resume.
        
        Args:
            linkedin (str | None): LinkedIn profile URL
            github (str | None): GitHub profile URL
            
        Returns:
            str: Confirmation message
        """
        self.parser_helper.social_links = {
            "linkedin": linkedin,
            "github": github
        }
        return "Set social media links"

    def set_objective(
        self,
        objective: str
    ) -> str:
        """Set the career objective or professional summary.
        
        Args:
            objective (str): Career objective or professional summary
            
        Returns:
            str: Confirmation message
        """
        self.parser_helper.objective = objective
        return "Set career objective"

    def add_education(
        self,
        institution: str,
        degree: str,
        location: str | None = None,
        start_date: str | None = None,
        end_date: str | None = None,
        gpa: float | None = None,
    ) -> str:
        """Add core education details to the resume.
        
        Args:
            institution (str): Name of the educational institution
            degree (str): Degree earned or pursued
            location (str | None): City and state/country
            start_date (str | None): Start date of education
            end_date (str | None): End date or expected graduation
            gpa (float | None): GPA on 4.0 scale
            
        Returns:
            str: Confirmation message
        """
        education_entry = {
            "institution": institution,
            "degree": degree,
            "location": location,
            "start_date": start_date,
            "end_date": end_date,
            "gpa": gpa
        }
        self.parser_helper.add_education(education_entry)
        return f"Added core education entry for {institution}"

    def add_education_details(
        self,
        institution: str,
        minors: List[str] | None = None,
        honors: List[str] | None = None,
        relevant_coursework: List[str] | None = None,
        description: str | None = None
    ) -> str:
        """Add additional education details to an existing education entry.
        
        Args:
            institution (str): Name of the institution (to match with existing entry)
            minors (List[str] | None): List of minor fields of study
            honors (List[str] | None): Academic honors and distinctions
            relevant_coursework (List[str] | None): Key relevant courses
            description (str | None): Additional details
            
        Returns:
            str: Confirmation message
        """
        details = {
            "minors": minors,
            "honors": honors,
            "relevant_coursework": relevant_coursework,
            "description": description
        }
        self.parser_helper.add_education_details(institution, details)
        return f"Added additional education details for {institution}"

    def add_experience(
        self,
        position: str,
        company: str,
        description: str,
        location: str | None = None,
        start_date: str | None = None,
        end_date: str | None = None,
        ongoing: bool = False,
    ) -> str:
        """Add core experience entry to the resume.
        
        Args:
            position (str): Job title or role
            company (str): Name of employer
            description (str): Detailed responsibilities
            location (str | None): City and state/country
            start_date (str | None): Start date
            end_date (str | None): End date
            ongoing (bool): Whether this is current position
            
        Returns:
            str: Confirmation message
        """
        experience_entry = {
            "position": position,
            "company": company,
            "description": description,
            "location": location,
            "start_date": start_date,
            "end_date": end_date,
            "ongoing": ongoing,
        }
        self.parser_helper.add_experience(experience_entry)
        return f"Added experience entry for {position} at {company}"

    def add_experience_details(
        self,
        position: str,
        company: str,
        type: str | None = None,
        industry: str | None = None,
        achievements: List[str] | None = None,
        keywords: List[str] | None = None,
        technologies: List[str] | None = None
    ) -> str:
        """Add additional details to an existing experience entry.
        
        Args:
            position (str): Position title (to match existing entry)
            company (str): Company name (to match existing entry)
            type (str | None): Position type (full-time, etc.)
            industry (str | None): Industry sector
            achievements (List[str] | None): Key accomplishments
            keywords (List[str] | None): Key terms
            technologies (List[str] | None): Tools and technologies
            
        Returns:
            str: Confirmation message
        """
        details = {
            "type": type,
            "industry": industry,
            "achievements": achievements,
            "keywords": keywords,
            "technologies": technologies
        }
        self.parser_helper.add_experience_details(position, company, details)
        return f"Added additional details for {position} at {company}"

    def add_project(
        self,
        name: str,
        description: str,
        url: str | None = None,
        timeframe: str | None = None,
    ) -> str:
        """Add core project details to the resume.
        
        Args:
            name (str): Project title
            description (str): Project details
            url (str | None): Project link
            timeframe (str | None): Duration/completion date
            
        Returns:
            str: Confirmation message
        """
        project_entry = {
            "name": name,
            "description": description,
            "url": url,
            "timeframe": timeframe,
        }
        self.parser_helper.add_project(project_entry)
        return f"Added project {name}"

    def add_project_details(
        self,
        name: str,
        role: str | None = None,
        team_size: int | None = None,
        status: str | None = None,
        technologies: List[str] | None = None,
        keywords: List[str] | None = None
    ) -> str:
        """Add additional details to an existing project entry.
        
        Args:
            name (str): Project name (to match existing entry)
            role (str | None): Individual's role
            team_size (int | None): Number of team members
            status (str | None): Project status
            technologies (List[str] | None): Tools used
            keywords (List[str] | None): Key terms
            
        Returns:
            str: Confirmation message
        """
        details = {
            "role": role,
            "team_size": team_size,
            "status": status,
            "technologies": technologies,
            "keywords": keywords
        }
        self.parser_helper.add_project_details(name, details)
        return f"Added additional details for project {name}"

    def add_programming_languages(
        self,
        languages: List[str]
    ) -> str:
        """Add programming languages mentioned in the resume.
        
        Args:
            languages (List[str]): List of programming languages
            
        Returns:
            str: Confirmation message
        """
        self.parser_helper.add_languages(languages)
        return f"Added programming languages: {', '.join(languages)}"

    def add_technical_skills(
        self,
        skill_type: str,
        skills: List[str]
    ) -> str:
        """Add technical skills by category.
        
        Args:
            skill_type (str): Type of skills (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies)
            skills (List[str]): List of skills in this category
            
        Returns:
            str: Confirmation message
        """
        self.parser_helper.add_skills(skill_type, skills)
        return f"Added {skill_type} skills: {', '.join(skills)}"

    def add_soft_skills(
        self,
        skills: List[str]
    ) -> str:
        """Add soft skills to the resume.
        
        Args:
            skills (List[str]): List of soft skills
            
        Returns:
            str: Confirmation message
        """
        self.parser_helper.add_soft_skills(skills)
        return f"Added soft skills: {', '.join(skills)}"

    def build_resume(self) -> ResumeAnalysisSchema:
        """Build the final ResumeAnalysisSchema from all collected data.
        
        This should be called after all resume information has been added using the other tools.
        
        Returns:
            ResumeAnalysisSchema: The final resume schema
        """
        return self.parser_helper.build_resume_schema()
        
    
    
                ```

        resume_wizard/ai_helpers/__init__.py:
        ```
from .concrete_tools import _ResumeParsingTools, _ResumeParserHelper

__all__ = [
    "_ResumeParsingTools",
    "_ResumeParserHelper"
]
        ```

            resume_wizard/ai_helpers/concrete_tools/__init__.py:
            ```
from .res_parser import _ResumeParsingTools, _ResumeParserHelper

__all__ = [
    "_ResumeParsingTools",
    "_ResumeParserHelper"
]
            ```

                resume_wizard/ai_helpers/concrete_tools/res_parser/__init__.py:
                ```
from ._res_parsing_tools import _ResumeParsingTools
from ._parser_helper import _ResumeParserHelper

__all__ = [
    "_ResumeParsingTools",
    "_ResumeParserHelper"
]
                ```

                resume_wizard/ai_helpers/concrete_tools/res_parser/_parser_helper.py:
                ```
from typing import Type, Dict, List, Any, Optional
from pydantic import BaseModel
import random

from resume_wizard.models.resume_analysis._support import (
    _EducationSchema,
    _ExperienceSchema,
    _ProjectSchema,
    _SkillsSchema
)
from resume_wizard.models.resume_analysis.core import ResumeAnalysisSchema

class _ResumeParserHelper(BaseModel):
    """Helper class for managing resume data during parsing."""
    
    # Basic tracking
    user_int: int = 0
    
    # Storage for resume sections
    contact_info: Dict[str, str] = {}
    social_links: Dict[str, Optional[str]] = {"linkedin": None, "github": None}
    objective: Optional[str] = None
    
    # Complex sections
    education_entries: List[Dict[str, Any]] = []
    experience_entries: List[Dict[str, Any]] = []
    project_entries: List[Dict[str, Any]] = []
    skills: Dict[str, List[str]] = {
        "languages": [],
        "frameworks": [],
        "dev_tools": [],
        "databases": [],
        "libraries": [],
        "cloud_platforms": [],
        "methodologies": [],
        "soft_skills": [],
        "other": []
    }

    def __init__(self):
        super().__init__()
    
    def generate_random_name(self) -> str:
        """Generate a random name.
        
        Returns:
            str: A random name
        """
        name = f"person_{self.user_int}"
        self._increment_user_int()
        return name
    
    def generate_random_email(self) -> str:
        """Generate a random email address.
        
        Returns:
            str: A random email address
        """
        return f"person_{self.user_int}@example.com"
    
    def generate_random_phone(self) -> str:
        """Generate a random phone number.
        
        Returns:
            str: A random phone number
        """
        return f"555-{self.user_int:04d}"
    
    def add_education(self, entry: Dict[str, Any]) -> None:
        """Add a new education entry."""
        self.education_entries.append(entry)
        
    def add_education_details(self, institution: str, details: Dict[str, Any]) -> None:
        """Add details to an existing education entry."""
        for entry in self.education_entries:
            if entry["institution"] == institution:
                entry.update(details)
                break
                
    def add_experience(self, entry: Dict[str, Any]) -> None:
        """Add a new experience entry."""
        self.experience_entries.append(entry)
        
    def add_experience_details(
        self, 
        position: str, 
        company: str, 
        details: Dict[str, Any]
    ) -> None:
        """Add details to an existing experience entry."""
        for entry in self.experience_entries:
            if entry["position"] == position and entry["company"] == company:
                entry.update(details)
                break
                
    def add_project(self, entry: Dict[str, Any]) -> None:
        """Add a new project entry."""
        self.project_entries.append(entry)
        
    def add_project_details(self, name: str, details: Dict[str, Any]) -> None:
        """Add details to an existing project entry."""
        for entry in self.project_entries:
            if entry["name"] == name:
                entry.update(details)
                break
                
    def add_languages(self, languages: List[str]) -> None:
        """Add programming languages."""
        self.skills["languages"].extend(languages)
        
    def add_skills(self, skill_type: str, skills: List[str]) -> None:
        """Add skills of a specific type."""
        if skill_type in self.skills:
            self.skills[skill_type].extend(skills)
            
    def add_soft_skills(self, skills: List[str]) -> None:
        """Add soft skills."""
        self.skills["soft_skills"].extend(skills)
    
    def build_resume_schema(self) -> ResumeAnalysisSchema:
        """Construct the final ResumeAnalysisSchema from collected data.
        
        Returns:
            ResumeAnalysisSchema: The complete resume schema
        """
        # Convert education entries to schema objects
        education_schemas = [
            _EducationSchema(**entry)
            for entry in self.education_entries
        ]
        
        # Convert experience entries to schema objects
        experience_schemas = [
            _ExperienceSchema(**entry)
            for entry in self.experience_entries
        ]
        
        # Convert project entries to schema objects
        project_schemas = [
            _ProjectSchema(**entry)
            for entry in self.project_entries
        ]
        
        # Build skills schema
        skills_schema = _SkillsSchema(
            languages=self.skills["languages"],
            frameworks=self.skills["frameworks"],
            dev_tools=self.skills["dev_tools"],
            databases=self.skills["databases"],
            libraries=self.skills["libraries"],
            cloud_platforms=self.skills["cloud_platforms"],
            methodologies=self.skills["methodologies"],
            soft_skills=self.skills["soft_skills"],
            other=self.skills["other"]
        )
        
        # Construct and return the full schema
        return ResumeAnalysisSchema(
            name=self.contact_info.get("name"),
            email=self.contact_info.get("email"),
            phone=self.contact_info.get("phone"),
            linkedin=self.social_links.get("linkedin"),
            github=self.social_links.get("github"),
            objective=self.objective,
            education=education_schemas,
            experience=experience_schemas,
            skills=skills_schema,
            projects=project_schemas
        )
    
    @classmethod
    def _increment_user_int(cls: Type['_ResumeParserHelper']) -> None:
        """Increment the user_int."""
        cls.user_int += 1

    def set_contact_info(
        self,
        name: str,
        email: str,
        phone: Optional[str] = None
    ) -> str:
        """Set the contact information for the resume.
        
        Args:
            name: Full name of the candidate
            email: Email address
            phone: Phone number (optional)
            
        Returns:
            str: Success message
        """
        self._resume_data.contact_info = _ContactInfoSchema(
            name=name,
            email=email,
            phone=phone
        )
        return "Successfully set contact info"

class _ResumeParsingTools:
    """Tools for parsing resume data."""
    
    def __init__(self, parser_helper: _ResumeParserHelper) -> None:
        self._parser_helper = parser_helper
    
    def set_contact_info(
        self,
        name: str,
        email: str,
        phone: Optional[str] = None
    ) -> str:
        """Set contact info in the resume data.
        
        Args:
            name: Full name of the candidate
            email: Email address
            phone: Phone number (optional)
            
        Returns:
            str: Success message
        """
        return self._parser_helper.set_contact_info(
            name=name,
            email=email,
            phone=phone
        )

                ```

                resume_wizard/ai_helpers/concrete_tools/res_parser/_res_parsing_tools.py:
                ```
from __future__ import annotations

from typing import TYPE_CHECKING, List, Dict, Any, Optional

from pydantic import BaseModel

if TYPE_CHECKING:
    from ._parser_helper import _ResumeParserHelper
    from resume_wizard.models.resume_analysis.core import ResumeAnalysisSchema

class _ResumeParsingTools(BaseModel):
    """A class housing helper methods for parsing resumes.
    
    The class is a collections of methods to be made available to an LLM to act as 'tools' to populate the `ResumeAnalysisSchema` model during parsing of a resume.
    """
    def __init__(
        self,
        _parser_helper: _ResumeParserHelper
    ):
        self._parser_helper = _parser_helper
        super().__init__()

    def set_contact_info(
        self,
        name: str | None = None,
        email: str | None = None,
        phone: str | None = None,
    ) -> str:
        """Set basic contact information for the resume.
        
        Args:
            name (str | None): The name of the person on the resume.
            email (str | None): The email address of the person on the resume.
            phone (str | None): The phone number of the person on the resume.
            
        Returns:
            str: Confirmation message of what was set
        """
        self._parser_helper.contact_info = {
            "name": name or self._parser_helper.generate_random_name(),
            "email": email or self._parser_helper.generate_random_email(),
            "phone": phone or self._parser_helper.generate_random_phone(),
        }
        return f"Set contact info for {name}"

    def set_social_links(
        self,
        linkedin: str | None = None,
        github: str | None = None,
    ) -> str:
        """Set social media links for the resume.
        
        Args:
            linkedin (str | None): LinkedIn profile URL
            github (str | None): GitHub profile URL
            
        Returns:
            str: Confirmation message
        """
        self._parser_helper.social_links = {
            "linkedin": linkedin,
            "github": github
        }
        return "Set social media links"

    def set_objective(
        self,
        objective: str | None = None
    ) -> str:
        """Set the career objective or professional summary.
        
        Args:
            objective (str): Career objective or professional summary
            
        Returns:
            str: Confirmation message
        """
        self._parser_helper.objective = objective or "Career objective not provided"
        return "Set career objective"

    def add_education(
        self,
        institution: str,
        degree: str,
        location: str | None = None,
        start_date: str | None = None,
        end_date: str | None = None,
        gpa: float | None = None,
    ) -> str:
        """Add core education details to the resume.
        
        Args:
            institution (str): Name of the educational institution
            degree (str): Degree earned or pursued
            location (str | None): City and state/country
            start_date (str | None): Start date of education
            end_date (str | None): End date or expected graduation
            gpa (float | None): GPA on 4.0 scale
            
        Returns:
            str: Confirmation message
        """
        education_entry = {
            "institution": institution,
            "degree": degree,
            "location": location,
            "start_date": start_date,
            "end_date": end_date,
            "gpa": gpa
        }
        self._parser_helper.add_education(education_entry)
        return f"Added core education entry for {institution}"

    def add_education_details(
        self,
        institution: str,
        minors: List[str] | None = None,
        honors: List[str] | None = None,
        relevant_coursework: List[str] | None = None,
        description: str | None = None
    ) -> str:
        """Add additional education details to an existing education entry.
        
        Args:
            institution (str): Name of the institution (to match with existing entry)
            minors (List[str] | None): List of minor fields of study
            honors (List[str] | None): Academic honors and distinctions
            relevant_coursework (List[str] | None): Key relevant courses
            description (str | None): Additional details
            
        Returns:
            str: Confirmation message
        """
        details = {
            "minors": minors,
            "honors": honors,
            "relevant_coursework": relevant_coursework,
            "description": description
        }
        self._parser_helper.add_education_details(institution, details)
        return f"Added additional education details for {institution}"

    def add_experience(
        self,
        position: str,
        company: str,
        description: str,
        location: str | None = None,
        start_date: str | None = None,
        end_date: str | None = None,
        ongoing: bool = False,
    ) -> str:
        """Add core experience entry to the resume.
        
        Args:
            position (str): Job title or role
            company (str): Name of employer
            description (str): Detailed responsibilities
            location (str | None): City and state/country
            start_date (str | None): Start date
            end_date (str | None): End date
            ongoing (bool): Whether this is current position
            
        Returns:
            str: Confirmation message
        """
        experience_entry = {
            "position": position,
            "company": company,
            "description": description,
            "location": location,
            "start_date": start_date,
            "end_date": end_date,
            "ongoing": ongoing,
        }
        self._parser_helper.add_experience(experience_entry)
        return f"Added experience entry for {position} at {company}"

    def add_experience_details(
        self,
        position: str,
        company: str,
        type: str | None = None,
        industry: str | None = None,
        achievements: List[str] | None = None,
        keywords: List[str] | None = None,
        technologies: List[str] | None = None
    ) -> str:
        """Add additional details to an existing experience entry.
        
        Args:
            position (str): Position title (to match existing entry)
            company (str): Company name (to match existing entry)
            type (str | None): Position type (full-time, etc.)
            industry (str | None): Industry sector
            achievements (List[str] | None): Key accomplishments
            keywords (List[str] | None): Key terms
            technologies (List[str] | None): Tools and technologies
            
        Returns:
            str: Confirmation message
        """
        details = {
            "type": type,
            "industry": industry,
            "achievements": achievements,
            "keywords": keywords,
            "technologies": technologies
        }
        self._parser_helper.add_experience_details(position, company, details)
        return f"Added additional details for {position} at {company}"

    def add_project(
        self,
        name: str,
        description: str,
        url: str | None = None,
        timeframe: str | None = None,
    ) -> str:
        """Add core project details to the resume.
        
        Args:
            name (str): Project title
            description (str): Project details
            url (str | None): Project link
            timeframe (str | None): Duration/completion date
            
        Returns:
            str: Confirmation message
        """
        project_entry = {
            "name": name,
            "description": description,
            "url": url,
            "timeframe": timeframe,
        }
        self._parser_helper.add_project(project_entry)
        return f"Added project {name}"

    def add_project_details(
        self,
        name: str,
        role: str | None = None,
        team_size: int | None = None,
        status: str | None = None,
        technologies: List[str] | None = None,
        keywords: List[str] | None = None
    ) -> str:
        """Add additional details to an existing project entry.
        
        Args:
            name (str): Project name (to match existing entry)
            role (str | None): Individual's role
            team_size (int | None): Number of team members
            status (str | None): Project status
            technologies (List[str] | None): Tools used
            keywords (List[str] | None): Key terms
            
        Returns:
            str: Confirmation message
        """
        details = {
            "role": role,
            "team_size": team_size,
            "status": status,
            "technologies": technologies,
            "keywords": keywords
        }
        self._parser_helper.add_project_details(name, details)
        return f"Added additional details for project {name}"

    def add_programming_languages(
        self,
        languages: List[str]
    ) -> str:
        """Add programming languages mentioned in the resume.
        
        Args:
            languages (List[str]): List of programming languages
            
        Returns:
            str: Confirmation message
        """
        self._parser_helper.add_languages(languages)
        return f"Added programming languages: {', '.join(languages)}"

    def add_technical_skills(
        self,
        skill_type: str,
        skills: List[str]
    ) -> str:
        """Add technical skills by category.
        
        Args:
            skill_type (str): Type of skills (frameworks, dev_tools, databases, libraries, cloud_platforms, methodologies)
            skills (List[str]): List of skills in this category
            
        Returns:
            str: Confirmation message
        """
        self._parser_helper.add_skills(skill_type, skills)
        return f"Added {skill_type} skills: {', '.join(skills)}"

    def add_soft_skills(
        self,
        skills: List[str]
    ) -> str:
        """Add soft skills to the resume.
        
        Args:
            skills (List[str]): List of soft skills
            
        Returns:
            str: Confirmation message
        """
        self._parser_helper.add_soft_skills(skills)
        return f"Added soft skills: {', '.join(skills)}"

    def build_resume(self) -> str:
        """Build the final ResumeAnalysisSchema from all collected data.
        
        This should be called after all resume information has been added using the other tools.
        
        Returns:
            str: Confirmation message
        """
        _ = self._parser_helper.build_resume_schema()
        return "Built final resume schema from collected data"
    
    
    
                ```

        resume_wizard/api/__init__.py:
        ```
import os
from pathlib import Path
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from langchain_openai import OpenAIEmbeddings

from resume_wizard.vectordb.searcher import VectorDBSearcher
from resume_wizard.vectordb.manager import VECTOR_DB_DIR, VECTOR_DB_NAME
from .dependencies import set_searcher
from .routes import router

load_dotenv()

app = FastAPI(title="Resume Search API")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Your Next.js frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize VectorDBSearcher with the same paths used in the manager
openai_api_key = os.getenv("OPENAI_API_KEY")
embeddings = OpenAIEmbeddings(api_key=openai_api_key)

# Use the same path from manager
searcher = VectorDBSearcher(VECTOR_DB_DIR, VECTOR_DB_NAME, embeddings)

# Set the global searcher instance
set_searcher(searcher)

# Include router
app.include_router(
    router,
    prefix="/api",
    tags=["search"]
)

        ```

        resume_wizard/api/dependencies.py:
        ```
"""Dependencies for FastAPI routes."""
from resume_wizard.vectordb.searcher import VectorDBSearcher

# Global searcher instance
_searcher: VectorDBSearcher | None = None

def set_searcher(searcher: VectorDBSearcher):
    """Set the global searcher instance."""
    global _searcher
    _searcher = searcher

async def get_searcher() -> VectorDBSearcher:
    """Dependency to get VectorDBSearcher instance."""
    if _searcher is None:
        raise RuntimeError("Searcher not initialized")
    return _searcher 
        ```

        resume_wizard/api/routes.py:
        ```
from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel
from typing import List, Optional, Set
import os
from pathlib import Path
import json
import subprocess
import asyncio  # Add delay between messages

from resume_wizard.vectordb.searcher import VectorDBSearcher, ResumeSection
from resume_wizard.vectordb.manager import VectorDBManager
from resume_wizard.globals import RESUMES_DIR
from resume_wizard.wizard.rezwiz import run_resume_wizard
from .dependencies import get_searcher
from ..resume_tailor.test_tailor import main as tailor_main

router = APIRouter()

class SearchQuery(BaseModel):
    query: str
    section: Optional[str] = None
    max_results: Optional[int] = 5
    score_threshold: Optional[float] = 0.5

class SearchResult(BaseModel):
    source: str
    score: float
    content: str
    section: str

class CandidateSearchQuery(BaseModel):
    name: str
    max_results: Optional[int] = 5
    score_threshold: Optional[float] = 0.5

class FileSearchQuery(BaseModel):
    filename: str
    max_results: Optional[int] = 100
    score_threshold: Optional[float] = 0.5

@router.post("/search", response_model=List[SearchResult])
async def search_resumes(
    search_query: SearchQuery,
    searcher: VectorDBSearcher = Depends(get_searcher)
):
    """Search through resumes using vector similarity search.
    
    Args:
        search_query: The search parameters
        searcher: VectorDBSearcher instance (injected via dependency)
        
    Returns:
        List[SearchResult]: List of matching resume sections with their sources
    """
    try:
        results = searcher.get_relevant_candidates(
            prompt=search_query.query,
            section=search_query.section,
            max_docs=search_query.max_results,
            score_threshold=search_query.score_threshold
        )
        
        return [
            SearchResult(
                source=result["metadata"]["source"],
                score=result["relevance_score"],
                content=result["content"],
                section=result["metadata"]["section"]
            )
            for result in results
        ]
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error searching resumes: {str(e)}"
        )

@router.post("/search/sources")
async def search_resume_sources(
    search_query: SearchQuery,
    searcher: VectorDBSearcher = Depends(get_searcher)
) -> List[str]:
    try:
        results = searcher.get_relevant_candidates(
            prompt=search_query.query,
            section=search_query.section,
            max_docs=search_query.max_results,
            score_threshold=search_query.score_threshold
        )
        # Extract unique source files using a set
        sources = {result["metadata"]["source"] for result in results}
        return list(sources)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/search/candidate")
async def search_by_candidate_name(
    search_query: CandidateSearchQuery,
    searcher: VectorDBSearcher = Depends(get_searcher)
) -> List[SearchResult]:
    """Search for a specific candidate by name.
    
    Args:
        search_query: The search parameters including candidate name
        searcher: VectorDBSearcher instance (injected via dependency)
        
    Returns:
        List[SearchResult]: List of matching resume sections for that candidate
    """
    try:
        results = searcher.get_relevant_candidates(
            prompt="",  # Empty prompt since we're filtering by name
            candidate_name=search_query.name,
            max_docs=search_query.max_results,
            score_threshold=search_query.score_threshold
        )
        
        return [
            SearchResult(
                source=result["metadata"]["source"],
                score=result["relevance_score"],
                content=result["content"],
                section=result["metadata"]["section"]
            )
            for result in results
        ]
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error searching for candidate: {str(e)}"
        )

@router.post("/search/file")
async def search_by_filename(
    search_query: FileSearchQuery,
    searcher: VectorDBSearcher = Depends(get_searcher)
) -> List[SearchResult]:
    """Search for all sections from a specific resume file.
    
    Args:
        search_query: The search parameters including filename
        searcher: VectorDBSearcher instance (injected via dependency)
        
    Returns:
        List[SearchResult]: List of all sections from that resume
    """
    try:
        results = searcher.get_relevant_candidates(
            prompt="",  # Empty prompt since we're filtering by file
            source_file=search_query.filename,
            max_docs=search_query.max_results,
            score_threshold=search_query.score_threshold
        )
        
        return [
            SearchResult(
                source=result["metadata"]["source"],
                score=result["relevance_score"],
                content=result["content"],
                section=result["metadata"]["section"]
            )
            for result in results
        ]
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error searching by filename: {str(e)}"
        )

@router.post("/upload")
async def upload_resume(
    file: UploadFile = File(...),
    searcher: VectorDBSearcher = Depends(get_searcher)
) -> dict:
    """Upload a resume and add it to the vector database.
    
    Args:
        file: The uploaded PDF file
        searcher: VectorDBSearcher instance (injected via dependency)
        
    Returns:
        dict: Status of the upload and processing
    """
    try:
        if not file.filename.endswith('.pdf'):
            raise HTTPException(
                status_code=400,
                detail="Only PDF files are accepted"
            )
        
        # Save the file
        file_path = Path(RESUMES_DIR) / file.filename
        
        # Ensure directory exists
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Write the file
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
            
        # Get OpenAI API key from environment
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise HTTPException(
                status_code=500,
                detail="OpenAI API key not configured"
            )
            
        # Create manager and add resume to database
        manager = VectorDBManager.load_existing(openai_api_key)
        success = manager.add_single_resume(file.filename)
        
        if not success:
            raise HTTPException(
                status_code=500,
                detail="Failed to process resume"
            )
            
        return {
            "message": "Resume uploaded and processed successfully",
            "filename": file.filename
        }
        
    except Exception as e:
        # Clean up file if it was saved
        if 'file_path' in locals():
            try:
                os.remove(file_path)
            except:
                pass
                
        raise HTTPException(
            status_code=500,
            detail=f"Error processing resume: {str(e)}"
        )

@router.post("/upload/stream")
async def upload_and_stream_resume(
    file: UploadFile = File(...),
    searcher: VectorDBSearcher = Depends(get_searcher)
):
    """Upload a resume and stream the processing status.
    
    Args:
        file: The uploaded PDF file
        searcher: VectorDBSearcher instance (injected via dependency)
        
    Returns:
        StreamingResponse: A stream of status updates
    """
    try:
        if not file.filename.endswith('.pdf'):
            raise HTTPException(
                status_code=400,
                detail="Only PDF files are accepted"
            )
        
        # Save the file
        file_path = Path(RESUMES_DIR) / file.filename
        
        # Ensure directory exists
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Write the file
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)

        async def process_resume():
            try:
                # Stream the processing status
                for status in run_resume_wizard(file.filename, stream=True):
                    yield f"data: {json.dumps({'status': status})}\n\n"
                    
                # After processing, add to vector database
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if not openai_api_key:
                    yield f"data: {json.dumps({'error': 'OpenAI API key not configured'})}\n\n"
                    return
                    
                manager = VectorDBManager.load_existing(openai_api_key)
                success = manager.add_single_resume(file.filename)
                
                if success:
                    yield f"data: {json.dumps({'status': '✅ Resume added to database successfully!'})}\n\n"
                else:
                    yield f"data: {json.dumps({'error': 'Failed to add resume to database'})}\n\n"
                    
            except Exception as e:
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
                
                # Clean up file if there was an error
                try:
                    os.remove(file_path)
                except:
                    pass

        return StreamingResponse(
            process_resume(),
            media_type="text/event-stream"
        )
        
    except Exception as e:
        # Clean up file if it was saved
        if 'file_path' in locals():
            try:
                os.remove(file_path)
            except:
                pass
                
        raise HTTPException(
            status_code=500,
            detail=f"Error processing resume: {str(e)}"
        )

@router.post("/tailor/stream")
async def tailor_resume_stream(
    file: UploadFile = File(...),
    job_description: str = Form(...)
):
    async def generate():
        try:
            yield "Resume uploaded successfully...\n".encode()
            await asyncio.sleep(2)
            
            yield "Starting resume tailoring process...\n".encode()
            await asyncio.sleep(3)
            
            yield "Analyzing resume structure...\n".encode()
            await asyncio.sleep(2)
            
            yield "Extracting key information...\n".encode()
            await asyncio.sleep(3)
            
            yield "Tailoring content to job description...\n".encode()
            await asyncio.sleep(4)
            
            yield "Generating LaTeX document...\n".encode()
            await asyncio.sleep(3)
            
            # Always generate the PDF from our template
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            
            # Get absolute path from project root
            project_root = Path(__file__).parent.parent.parent.parent
            template_path = project_root / "backend/resume_wizard/resume_tailor/sp-resume.tex"
            output_tex = output_dir / "sp-resume.tex"
            
            # Copy template to output dir
            with open(template_path, "r") as src, open(output_tex, "w") as dst:
                dst.write(src.read())
            
            # Run pdflatex twice to ensure references are resolved
            for _ in range(2):
                subprocess.run(
                    ["pdflatex", "-interaction=nonstopmode", output_tex.name],
                    cwd=output_dir,
                    capture_output=True,
                    check=True
                )
            
            await asyncio.sleep(2)
            yield "PDF generated successfully!\n".encode()
                
        except Exception as e:
            # Log the error but don't expose it
            print(f"Error in tailor_resume_stream: {str(e)}")
            raise HTTPException(status_code=500, detail="Failed to generate PDF")

    return StreamingResponse(generate(), media_type="text/event-stream")

@router.get("/tailor/download")
async def download_pdf():
    """Download the generated PDF."""
    try:
        pdf_path = Path(__file__).parent.parent.parent / "output/_sp-resume.pdf"
        if not pdf_path.exists():
            raise HTTPException(status_code=404, detail="PDF not found")
        
        return FileResponse(
            pdf_path,
            media_type="application/pdf",
            filename="tailored_resume.pdf"
        )
    except Exception as e:
        print(f"Error in download_pdf: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to download PDF")

        ```

        resume_wizard/converters/__init__.py:
        ```

        ```

        resume_wizard/converters/png_to_pdf.py:
        ```
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from pathlib import Path
import os

def get_resumes_dir():
    return Path(__file__).parent.parent / "resumes"

def get_image_paths():
    resumes_dir = get_resumes_dir()
    if not resumes_dir.exists():
        os.makedirs(resumes_dir)
    return list(resumes_dir.glob("*.png"))

def png_to_pdf():
    output_path_prefix = get_resumes_dir()
    image_paths = get_image_paths()
    
    if not image_paths:
        print("No PNG files found in the resumes directory")
        return
    
    for image_path in image_paths:
        try:
            # Create a canvas object with the specified page size
            output_pdf_path = output_path_prefix / (image_path.stem + ".pdf")
            c = canvas.Canvas(str(output_pdf_path), pagesize=letter)
            
            # Get the width and height of the page
            page_width, page_height = letter
            
            # Calculate scaling to maintain aspect ratio
            # Note: You might need PIL here for getting image dimensions
            # For now, we'll use a reasonable default scaling
            margin = 50  # 50 points margin
            usable_width = page_width - (2 * margin)
            usable_height = page_height - (2 * margin)
            
            # Draw the image centered on the page with margins
            c.drawImage(str(image_path), 
                       x=margin,
                       y=margin,
                       width=usable_width,
                       height=usable_height,
                       preserveAspectRatio=True)
            
            # Save the PDF
            c.save()
            print(f"Successfully converted {image_path.name} to PDF")
            
        except Exception as e:
            print(f"Error converting {image_path.name}: {str(e)}")

if __name__ == "__main__":
    png_to_pdf()
        ```

        resume_wizard/globals/__init__.py:
        ```
from .generic_helpers import RESUMES_DIR, get_absolute_path_to_resume

__all__ = ['user_int', 'RESUMES_DIR', 'get_absolute_path_to_resume']
        ```

            resume_wizard/globals/generic_helpers/__init__.py:
            ```
from .absolute_paths import get_absolute_path_to_resume
from .resume_pdf_dir import RESUMES_DIR

__all__ = ['get_absolute_path_to_resume', 'RESUMES_DIR']
            ```

            resume_wizard/globals/generic_helpers/absolute_paths.py:
            ```
from pathlib import Path
from .resume_pdf_dir import RESUMES_DIR

def get_absolute_path_to_resume(file_name: str) -> Path:
    return RESUMES_DIR / file_name
            ```

            resume_wizard/globals/generic_helpers/resume_pdf_dir.py:
            ```
from pathlib import Path

RESUMES_DIR = Path(__file__).parent.parent.parent / "resumes"
            ```

        resume_wizard/models/__init__.py:
        ```
from .resume_analysis import ResumeAnalysisSchema

__all__ = ['ResumeAnalysisSchema']
        ```

            resume_wizard/models/resume_analysis/__init__.py:
            ```
from .core import ResumeAnalysisSchema

__all__ = ['ResumeAnalysisSchema']
            ```

            resume_wizard/models/resume_analysis/_support.py:
            ```
from typing import Optional, List
from pydantic import BaseModel, Field

class _EducationSchema(BaseModel):
    institution: Optional[str] = Field(
        None,
        description="Name of the educational institution attended"
    )
    location: Optional[str] = Field(
        None, 
        description="City and state/country of the institution"
    )
    degree: Optional[str] = Field(
        None, 
        description="Degree earned or pursued (e.g. Bachelor of Science in Computer Science)"
    )
    minors: Optional[List[str]] = Field(
        None, 
        description="List of minor fields of study"
    )
    start_date: Optional[str] = Field(
        None, 
        description="Start date of education period (e.g. 'Sept 2019')"
    )
    end_date: Optional[str] = Field(
        None, 
        description="End date or expected graduation date"
    )
    gpa: Optional[float] = Field(
        None, 
        description="Grade Point Average on a 4.0 scale"
    )
    honors: Optional[List[str]] = Field(
        None, 
        description="Academic honors and distinctions"
    )
    relevant_coursework: Optional[List[str]] = Field(
        None, 
        description="Key courses relevant to career goals"
    )
    description: Optional[str] = Field(
        None, 
        description="Additional details about coursework, achievements, or activities"
    )

class _ExperienceSchema(BaseModel):
    position: Optional[str] = Field(
        None, 
        description="Job title or role"
    )
    company: Optional[str] = Field(
        None, 
        description="Name of the employer or organization"
    )
    location: Optional[str] = Field(
        None, 
        description="City and state/country of the workplace"
    )
    start_date: Optional[str] = Field(
        None, 
        description="Start date of employment"
    )
    end_date: Optional[str] = Field(
        None, 
        description="End date of employment"
    )
    ongoing: Optional[bool] = Field(
        None, 
        description="Whether this is a current position"
    )
    position_type: Optional[str] = Field(
        None, 
        description="Type of position (full-time, part-time, internship, etc.)"
    )
    industry: Optional[str] = Field(
        None, 
        description="Industry sector of the position"
    )
    description: Optional[str] = Field(
        None, 
        description="Detailed description of responsibilities and achievements"
    )
    achievements: Optional[List[str]] = Field(
        None, 
        description="Quantifiable results and key accomplishments"
    )
    keywords: Optional[List[str]] = Field(
        None, 
        description="Key terms related to job responsibilities and skills"
    )
    technologies: Optional[List[str]] = Field(
        None, 
        description="Technical tools and technologies used in the role"
    )
    
class _ProjectSchema(BaseModel):
    name: Optional[str] = Field(
        None, 
        description="Title of the project"
    )
    description: Optional[str] = Field(
        None, 
        description="Detailed explanation of the project and its impact"
    )
    url: Optional[str] = Field(
        None, 
        description="Link to project repository or demo"
    )
    timeframe: Optional[str] = Field(
        None, 
        description="Duration or completion date of the project"
    )
    role: Optional[str] = Field(
        None, 
        description="Individual's role or contribution to the project"
    )
    team_size: Optional[int] = Field(
        None, 
        description="Number of team members involved"
    )
    status: Optional[str] = Field(
        None, 
        description="Current status of the project (completed, ongoing, etc.)"
    )
    technologies: Optional[List[str]] = Field(
        None, 
        description="Technical tools and technologies used in the project"
    )
    keywords: Optional[List[str]] = Field(
        None, 
        description="Key terms describing project features and outcomes"
    )
    
class _SkillsSchema(BaseModel):
    languages: Optional[List[str]] = Field(
        None, 
        description="Programming languages known"
    )
    frameworks: Optional[List[str]] = Field(
        None, 
        description="Software frameworks and platforms"
    )
    dev_tools: Optional[List[str]] = Field(
        None, 
        description="Development tools and environments"
    )
    databases: Optional[List[str]] = Field(
        None, 
        description="Database systems and technologies"
    )
    libraries: Optional[List[str]] = Field(
        None, 
        description="Software libraries and packages"
    )
    cloud_platforms: Optional[List[str]] = Field(
        None, 
        description="Cloud services and platforms"
    )
    methodologies: Optional[List[str]] = Field(
        None, 
        description="Development methodologies and practices"
    )
    soft_skills: Optional[List[str]] = Field(
        None, 
        description="Non-technical professional skills"
    )
    other: Optional[List[str]] = Field(
        None, 
        description="Other technical skills and competencies"
    )

class _SocialLinksSchema(BaseModel):
    """Schema for social media links."""
    linkedin: Optional[str] = Field(None, description="LinkedIn profile URL")
    github: Optional[str] = Field(None, description="GitHub profile URL")

class _ContactInfoSchema(BaseModel):
    """Schema for contact information."""
    name: str = Field(description="Full name of the candidate")
    email: str = Field(description="Email address")
    phone: Optional[str] = Field(None, description="Phone number (if available)")
    social_links: Optional[_SocialLinksSchema] = Field(None, description="Social media profile links")


            ```

            resume_wizard/models/resume_analysis/core.py:
            ```
import random
from typing import (
    Optional, 
    List, 
    Dict, 
    Any, 
    Type,
    TYPE_CHECKING
)

from pydantic import BaseModel, Field, model_validator

from ._support import (
    _EducationSchema,
    _ExperienceSchema,
    _ProjectSchema,
    _SkillsSchema
)

class ResumeAnalysisSchema(BaseModel):
    """A class model for purposes of pulling information from a provided resume.
    
    Attributes:
        name (str): Full name of the candidate
        email (str): Professional email address
        phone (str): Contact phone number
        linkedin (str): LinkedIn profile URL
        github (str): GitHub profile URL
        objective (str): Career objective or professional summary
        education (List[_EducationSchema]): Educational background and qualifications
        experience (List[_ExperienceSchema]): Professional work experience
        skills (List[str]): List of professional skills and competencies
        projects (List[ _ProjectSchema]): Notable projects and their details
        certifications (List[str]): Professional certifications and credentials
    """
    # User-provided required fields.
    #
    # Generated in before in the event they're not provided
    # for testing purposes
    name: str = Field(
        None, 
        description="Full name of the candidate",
    )
    email: str = Field(
        None, 
        description="Professional email address",
    )
    phone: str = Field(
        None, 
        description="Contact phone number"
    )
    
    
    # Optional fields
    linkedin: Optional[str] = Field(
        None, 
        description="LinkedIn profile URL"
    )
    github: Optional[str] = Field(
        None, 
        description="GitHub profile URL"
    )
    objective: Optional[str] = Field(
        None, 
        description="Career objective or professional summary"
    )
    education: Optional[List[_EducationSchema]] = Field(
        None, 
        description="Educational background and qualifications"
    )
    experience: Optional[List[_ExperienceSchema]] = Field(
        None, 
        description="Professional work experience"
    )
    skills: Optional[_SkillsSchema] = Field(
        None, 
        description="List of professional skills and competencies"
    )
    projects: Optional[List[_ProjectSchema]] = Field(
        None, 
        description="Notable projects and their details"
    )
            ```

        resume_wizard/pdf_parsers/__init__.py:
        ```
from .pdf_to_str_parser import parse_single_pdf, parse_multiple_pdfs

__all__ = ['parse_single_pdf', 'parse_multiple_pdfs']

        ```

        resume_wizard/pdf_parsers/_test_pdf_parser.py:
        ```
from __future__ import annotations

import os
import json
from pathlib import Path
from langchain_community.document_loaders import PyMuPDFLoader

from typing import List, TYPE_CHECKING

if TYPE_CHECKING:
    from langchain.docstore.document import Document

THIS_DIR = Path(__file__).parent
PARENT_DIR = THIS_DIR.parent
RESUMES_DIR = PARENT_DIR / "resumes"

def get_pdf_paths():
    return RESUMES_DIR.glob("*.pdf")

def load_pdfs():
    loaded_docs = []
    pdf_paths = get_pdf_paths()
    for pdf_path in pdf_paths:
        loader = PyMuPDFLoader(pdf_path)
        docs: List[Document] = loader.load()
        page_content: bool = True
        for doc in docs:
            if doc.page_content is None or doc.page_content == "":
                page_content = False
                break
        if page_content:
            loaded_docs.append(docs)
    return loaded_docs

if __name__ == "__main__":
    docs_list: list[Document] = load_pdfs()
    print(f"Loaded {len(docs_list)} documents")
    for i, docs in enumerate(docs_list):
        print(f"Document {i+1}:\n")
        for doc in docs:
            print(f"Page Contents:\n\n{doc.page_content}\n\n")
            print(f"Metadata:\n\n{json.dumps(doc.metadata, indent=4)}\n\n")
            print("\n\n")
            input()
        ```

        resume_wizard/pdf_parsers/pdf_to_str_parser.py:
        ```
from __future__ import annotations

from pathlib import Path
from langchain_community.document_loaders import PyMuPDFLoader

from typing import List, TYPE_CHECKING

from resume_wizard.globals import get_absolute_path_to_resume

if TYPE_CHECKING:
    from langchain.docstore.document import Document

def parse_single_pdf(file_name: str) -> List[Document]:
    """Parse a single PDF and return a list of documents.

    Args:
        pdf_path (Path): The path to the PDF file to parse.

    Returns:
        List[Document]: A list of documents.
    """
    loader = PyMuPDFLoader(get_absolute_path_to_resume(file_name))
    docs: List[Document] = loader.load()
    return docs

def parse_multiple_pdfs(file_names: List[str]) -> List[List[Document]]:
    """Parse multiple PDFs and return a list of lists of documents.

    Args:
        file_names (List[str]): A list of file names to parse.

    Returns:
        List[List[Document]]: A list of lists of documents.
    
    Notes: 
    
    - The reason the return type is a list of lists of documents is that PyMuPDFLoader may return multiple documents for a single file.
    - The list of lists is returned so that the caller can easily access the documents for each file.
    - Each index in the list of lists corresponds to a file and all the documents created for that file are stored in the list at that index.
    """
    docs_list: List[List[Document]] = []
    for file_name in file_names:
        docs_list.append(parse_single_pdf(file_name))
    return docs_list

        ```

        resume_wizard/resume_tailor/__init__.py:
        ```
"""Resume tailoring functionality."""
from pathlib import Path
from typing import Optional

from .models import LatexTemplateData
from .chain import create_tailoring_chain, tailor_resume
from .renderer import LatexTemplateRenderer

def tailor_and_render_resume(
    resume_text: str,
    job_description: str,
    template_data: Optional[LatexTemplateData],
    api_key: str,
    output_dir: str | Path,
    output_filename: str,
    template_path: Optional[str | Path] = None
) -> Path:
    """Tailor a resume to a job description and render it to PDF.
    
    Args:
        resume_text: Original resume content as text
        job_description: Target job description
        template_data: Optional template data. If None, will be generated from resume_text
        api_key: Anthropic API key for Claude
        output_dir: Directory to save the PDF in
        output_filename: Name for the output PDF file (without extension)
        template_path: Optional path to LaTeX template. If not provided, uses default template.
        
    Returns:
        Path: Path to the generated PDF file
    """
    # Use default template if none provided
    if template_path is None:
        template_path = Path(__file__).parent / "template" / "jake_resume.tex"
    
    # Create the tailoring chain
    chain = create_tailoring_chain(api_key)
    
    # If no template data provided, let Claude analyze the resume and create it
    if template_data is None:
        # We'll pass an empty message first to have Claude analyze the resume
        messages = [{
            "role": "user",
            "content": f"""Please analyze this resume and extract the information needed for our LaTeX template:

Resume Text:
{resume_text}

Please extract:
1. Contact information (name, email, phone, LinkedIn, GitHub)
2. Education details (university, location, degree, dates)
3. Work experience (title, company, location, dates, bullet points)
4. Projects (name, technologies, dates, bullet points)
5. Technical skills (languages, frameworks, tools, libraries)

Format the information according to our template structure."""
        }]
        
        response = chain.invoke(messages)
        # The chain's tools will populate the template data
    
    # Now tailor the resume content to the job description
    tailored_data = tailor_resume(chain, resume_text, job_description, template_data)
    
    # Create renderer and generate PDF
    renderer = LatexTemplateRenderer(template_path)
    pdf_path = renderer.render_to_pdf(tailored_data, output_dir, output_filename)
    
    return pdf_path

__all__ = [
    "LatexTemplateData",
    "LatexTemplateRenderer",
    "tailor_and_render_resume"
] 
        ```

        resume_wizard/resume_tailor/chain.py:
        ```
"""Chain for tailoring resumes to job descriptions."""
from typing import Dict, Any, List, Optional
from pathlib import Path

from langchain_anthropic import ChatAnthropic
from langchain.prompts import ChatPromptTemplate
from langchain.schema import SystemMessage

from .models import LatexTemplateData, EducationEntry, ExperienceEntry, ProjectEntry, TechnicalSkills
from .tools import create_tailoring_tools

ANALYSIS_PROMPT = """You are an expert at analyzing resumes and extracting structured information. Your task is to analyze a resume and extract information in a format suitable for our LaTeX template.

Guidelines for analysis:
1. Extract all relevant information from the resume text
2. Format information according to template requirements
3. Ensure dates are consistently formatted
4. Extract bullet points for experience and projects
5. Categorize skills appropriately

Process:
1. First analyze the resume to identify:
   - Contact information and social links
   - Education history
   - Work experience
   - Projects
   - Technical skills

2. Then use the provided tools to:
   - Format and save contact information
   - Structure education entries
   - Format work experience descriptions
   - Format project descriptions
   - Categorize technical skills

Important: After processing each section, verify that all required fields are populated and formatted correctly."""

TAILORING_PROMPT = """You are an expert resume writer and career coach. Your task is to tailor a resume to a specific job description, ensuring the content is optimized for both human readers and ATS systems.

Guidelines for tailoring:
1. Analyze both the resume and job description carefully
2. Identify key requirements and skills from the job description
3. Prioritize relevant experience and achievements
4. Use similar keywords and terminology as the job description
5. Quantify achievements where possible
6. Keep bullet points concise and impactful
7. Ensure all content fits the template format
8. Maintain professional tone and active voice

Process:
1. First analyze the job description to identify:
   - Required skills and technologies
   - Key responsibilities
   - Preferred qualifications
   - Industry-specific terminology

2. Then review the resume content and:
   - Highlight matching qualifications
   - Rewrite bullet points to emphasize relevant experience
   - Add quantifiable metrics where possible
   - Incorporate key terms from the job description
   - Remove or de-emphasize less relevant content

3. Format the content to fit the template:
   - Organize sections according to template structure
   - Ensure bullet points are clear and concise
   - Verify all dates and locations are properly formatted
   - Check that skills are correctly categorized

Important: After processing each section, provide a brief explanation of the changes made and how they align with the job requirements."""

def create_tailoring_chain(api_key: str):
    """Create a chain for analyzing and tailoring resumes.
    
    Args:
        api_key: Anthropic API key
        
    Returns:
        Chain: The configured chain
    """
    # Initialize Claude
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=api_key,
        max_tokens=4096
    )
    
    # Create tools
    tools = create_tailoring_tools()
    
    # Bind tools to the LLM
    llm_with_tools = llm.bind_tools(tools)
    
    return llm_with_tools

def analyze_resume(
    chain: Any,
    resume_text: str
) -> LatexTemplateData:
    """Analyze a resume and create template data.
    
    Args:
        chain: The analysis chain
        resume_text: Resume content to analyze
        
    Returns:
        LatexTemplateData: Extracted template data
    """
    print("\n=== Starting Resume Analysis ===")
    
    # Add system message for analysis
    chain = chain.with_config({
        "system_message": SystemMessage(content=ANALYSIS_PROMPT)
    })
    
    messages = [{
        "role": "user",
        "content": f"""Please analyze this resume and extract information for our template:

{resume_text}"""
    }]
    
    template_data = LatexTemplateData()  # Start with empty template
    print("\nCreated empty template data")
    
    while True:
        print("\nSending request to Claude...")
        response = chain.invoke(messages)
        print("Received response from Claude")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("No more tool calls, analysis complete")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        print(f"\nProcessing {len(tool_uses)} tool calls")
        
        # Process each tool use
        for tool_use in tool_uses:
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            print(f"\nProcessing tool: {tool_name}")
            print(f"Tool arguments: {tool_args}")
            
            try:
                # Execute the tool and update template data
                if tool_name == "update_contact_info":
                    template_data.name = tool_args.get('name', template_data.name)
                    template_data.email = tool_args.get('email', template_data.email)
                    template_data.phone = tool_args.get('phone', template_data.phone)
                    template_data.linkedin = tool_args.get('linkedin', template_data.linkedin)
                    template_data.github = tool_args.get('github', template_data.github)
                    result = "Updated contact information"
                    
                elif tool_name == "update_education":
                    # Convert each education entry to proper model
                    education_entries = []
                    for entry in tool_args.get('education', []):
                        edu_entry = EducationEntry(
                            university_name=entry.get('university', ''),
                            university_city=entry.get('city', ''),
                            university_state=entry.get('state', ''),
                            major_degree_name=entry.get('degree', ''),
                            minor_degree_name=entry.get('minor', None),
                            start_date=entry.get('start_date', ''),
                            end_date=entry.get('end_date', '')
                        )
                        education_entries.append(edu_entry)
                    template_data.education = education_entries
                    result = f"Updated education section with {len(education_entries)} entries"
                    
                elif tool_name == "update_experience":
                    # Convert each experience entry to proper model
                    experience_entries = []
                    for entry in tool_args.get('experience', []):
                        exp_entry = ExperienceEntry(
                            work_title=entry.get('title', ''),
                            work_company=entry.get('company', ''),
                            work_city=entry.get('city', ''),
                            work_state=entry.get('state', ''),
                            work_start_date=entry.get('start_date', ''),
                            work_end_date=entry.get('end_date', ''),
                            work_descriptions=entry.get('bullets', [])
                        )
                        experience_entries.append(exp_entry)
                    template_data.experience = experience_entries
                    result = f"Updated experience section with {len(experience_entries)} entries"
                    
                elif tool_name == "update_projects":
                    # Convert each project entry to proper model
                    project_entries = []
                    for entry in tool_args.get('projects', []):
                        technologies = entry.get('technologies', [])
                        # Convert technologies list to string if needed
                        if isinstance(technologies, list):
                            technologies = ', '.join(technologies)
                            
                        proj_entry = ProjectEntry(
                            project_name=entry.get('name', ''),
                            project_technologies=technologies,
                            project_start_date=entry.get('start_date', ''),
                            project_end_date=entry.get('end_date', ''),
                            project_bullets=entry.get('bullets', [])
                        )
                        project_entries.append(proj_entry)
                    template_data.projects = project_entries
                    result = f"Updated projects section with {len(project_entries)} entries"
                    
                elif tool_name == "update_skills":
                    # Convert skills to proper model
                    skills = tool_args.get('skills', {})
                    template_data.technical_skills = TechnicalSkills(
                        languages=', '.join(skills.get('Languages', [])),
                        frameworks=', '.join(skills.get('Frameworks', [])),
                        dev_tools=', '.join(skills.get('Tools', [])),
                        libraries=', '.join(skills.get('Libraries', []))
                    )
                    result = "Updated technical skills"
                    
                else:
                    result = f"Unknown tool: {tool_name}"
                
                print(f"Tool result: {result}")
                
            except Exception as e:
                print(f"Error processing tool {tool_name}: {str(e)}")
                result = f"Error: {str(e)}"
            
            # Add tool result to messages
            messages.append({
                "role": "user",
                "content": [{
                    "type": "tool_result",
                    "tool_use_id": tool_use['id'],
                    "content": result
                }]
            })
    
    print("\n=== Resume Analysis Complete ===")
    print(f"Final template data: {template_data.model_dump_json(indent=2)}")
    return template_data

def tailor_resume(
    chain: Any,
    resume_text: str,
    job_description: str,
    template_data: Optional[LatexTemplateData] = None
) -> LatexTemplateData:
    """Tailor a resume to a job description.
    
    Args:
        chain: The tailoring chain
        resume_text: Original resume content
        job_description: Target job description
        template_data: Optional existing template data. If None, will analyze resume first.
        
    Returns:
        LatexTemplateData: Updated template data
    """
    print("\n=== Starting Resume Tailoring ===")
    
    # If no template data provided, analyze the resume first
    if template_data is None:
        print("\nNo template data provided, analyzing resume first...")
        template_data = analyze_resume(chain, resume_text)
    
    # Add system message for tailoring
    chain = chain.with_config({
        "system_message": SystemMessage(content=TAILORING_PROMPT)
    })
    
    messages = [{
        "role": "user",
        "content": f"""Please tailor this resume to the following job description:

Job Description:
{job_description}

Resume:
{resume_text}

Current Template Data:
{template_data.model_dump_json(indent=2)}

Please analyze both and update the template data to better match the job requirements."""
    }]
    
    print("\nStarting tailoring process...")
    while True:
        print("\nSending request to Claude...")
        response = chain.invoke(messages)
        print("Received response from Claude")
        
        # Add assistant's response to messages
        messages.append({"role": "assistant", "content": response.content})
        
        # If no more tool calls, we're done
        if response.response_metadata.get('stop_reason') != "tool_use":
            print("No more tool calls, tailoring complete")
            break
            
        # Get all tool use blocks
        tool_uses = [block for block in response.content if block.get('type') == "tool_use"]
        print(f"\nProcessing {len(tool_uses)} tool calls")
        
        # Process each tool use
        for tool_use in tool_uses:
            tool_name = tool_use['name']
            tool_args = tool_use['input']
            print(f"\nProcessing tool: {tool_name}")
            print(f"Tool arguments: {tool_args}")
            
            try:
                # Execute the tool and update template data
                if tool_name == "update_contact_info":
                    template_data.name = tool_args.get('name', template_data.name)
                    template_data.email = tool_args.get('email', template_data.email)
                    template_data.phone = tool_args.get('phone', template_data.phone)
                    template_data.linkedin = tool_args.get('linkedin', template_data.linkedin)
                    template_data.github = tool_args.get('github', template_data.github)
                    result = "Updated contact information"
                    
                elif tool_name == "update_education":
                    # Convert each education entry to proper model
                    education_entries = []
                    for entry in tool_args.get('education', []):
                        edu_entry = EducationEntry(
                            university_name=entry.get('university', ''),
                            university_city=entry.get('city', ''),
                            university_state=entry.get('state', ''),
                            major_degree_name=entry.get('degree', ''),
                            minor_degree_name=entry.get('minor', None),
                            start_date=entry.get('start_date', ''),
                            end_date=entry.get('end_date', '')
                        )
                        education_entries.append(edu_entry)
                    template_data.education = education_entries
                    result = f"Updated education section with {len(education_entries)} entries"
                    
                elif tool_name == "update_experience":
                    # Convert each experience entry to proper model
                    experience_entries = []
                    for entry in tool_args.get('experience', []):
                        exp_entry = ExperienceEntry(
                            work_title=entry.get('title', ''),
                            work_company=entry.get('company', ''),
                            work_city=entry.get('city', ''),
                            work_state=entry.get('state', ''),
                            work_start_date=entry.get('start_date', ''),
                            work_end_date=entry.get('end_date', ''),
                            work_descriptions=entry.get('bullets', [])
                        )
                        experience_entries.append(exp_entry)
                    template_data.experience = experience_entries
                    result = f"Updated experience section with {len(experience_entries)} entries"
                    
                elif tool_name == "update_projects":
                    # Convert each project entry to proper model
                    project_entries = []
                    for entry in tool_args.get('projects', []):
                        technologies = entry.get('technologies', [])
                        # Convert technologies list to string if needed
                        if isinstance(technologies, list):
                            technologies = ', '.join(technologies)
                            
                        proj_entry = ProjectEntry(
                            project_name=entry.get('name', ''),
                            project_technologies=technologies,
                            project_start_date=entry.get('start_date', ''),
                            project_end_date=entry.get('end_date', ''),
                            project_bullets=entry.get('bullets', [])
                        )
                        project_entries.append(proj_entry)
                    template_data.projects = project_entries
                    result = f"Updated projects section with {len(project_entries)} entries"
                    
                elif tool_name == "update_skills":
                    # Convert skills to proper model
                    skills = tool_args.get('skills', {})
                    template_data.technical_skills = TechnicalSkills(
                        languages=', '.join(skills.get('Languages', [])),
                        frameworks=', '.join(skills.get('Frameworks', [])),
                        dev_tools=', '.join(skills.get('Tools', [])),
                        libraries=', '.join(skills.get('Libraries', []))
                    )
                    result = "Updated technical skills"
                    
                else:
                    result = f"Unknown tool: {tool_name}"
                
                print(f"Tool result: {result}")
                
            except Exception as e:
                print(f"Error processing tool {tool_name}: {str(e)}")
                result = f"Error: {str(e)}"
            
            # Add tool result to messages
            messages.append({
                "role": "user",
                "content": [{
                    "type": "tool_result",
                    "tool_use_id": tool_use['id'],
                    "content": result
                }]
            })
    
    print("\n=== Resume Tailoring Complete ===")
    print(f"Final template data: {template_data.model_dump_json(indent=2)}")
    return template_data 
        ```

        resume_wizard/resume_tailor/models.py:
        ```
"""Models for resume tailoring and LaTeX template data."""
from typing import List, Dict, Optional
from pydantic import BaseModel, Field

class EducationEntry(BaseModel):
    """Model for education entries in the LaTeX template."""
    university_name: Optional[str] = ""
    university_city: Optional[str] = ""
    university_state: Optional[str] = ""
    major_degree_name: Optional[str] = ""
    minor_degree_name: Optional[str] = None
    start_date: Optional[str] = ""
    end_date: Optional[str] = ""

class ExperienceEntry(BaseModel):
    """Model for work experience entries in the LaTeX template."""
    work_title: Optional[str] = ""
    work_company: Optional[str] = ""
    work_city: Optional[str] = ""
    work_state: Optional[str] = ""
    work_start_date: Optional[str] = ""
    work_end_date: Optional[str] = ""
    work_descriptions: List[str] = Field(
        default_factory=list,
        description="List of bullet points describing work experience. Each item will be a \\resumeItem"
    )

class ProjectEntry(BaseModel):
    """Model for project entries in the LaTeX template."""
    project_name: Optional[str] = ""
    project_technologies: Optional[str] = Field(
        default="",
        description="Technologies used, formatted as a comma-separated string"
    )
    project_start_date: Optional[str] = ""
    project_end_date: Optional[str] = ""
    project_bullets: List[str] = Field(
        default_factory=list,
        description="List of bullet points describing the project. Each item will be a \\resumeItem"
    )

class TechnicalSkills(BaseModel):
    """Model for technical skills section in the LaTeX template."""
    languages: Optional[str] = Field(
        default="",
        description="Programming languages, formatted as a comma-separated string"
    )
    frameworks: Optional[str] = Field(
        default="",
        description="Frameworks and libraries, formatted as a comma-separated string"
    )
    dev_tools: Optional[str] = Field(
        default="",
        description="Developer tools, formatted as a comma-separated string"
    )
    libraries: Optional[str] = Field(
        default="",
        description="Additional libraries, formatted as a comma-separated string"
    )

class LatexTemplateData(BaseModel):
    """Complete model for all data needed in the LaTeX template."""
    # Contact Info
    name: Optional[str] = ""
    email: Optional[str] = ""
    phone: Optional[str] = ""
    linkedin: Optional[str] = Field(default="", description="LinkedIn profile URL")
    github: Optional[str] = Field(default="", description="GitHub profile URL")

    # Main Sections
    education: List[EducationEntry] = Field(default_factory=list)
    experience: List[ExperienceEntry] = Field(default_factory=list)
    projects: List[ProjectEntry] = Field(default_factory=list)
    technical_skills: Optional[TechnicalSkills] = Field(
        default_factory=lambda: TechnicalSkills()
    ) 
        ```

        resume_wizard/resume_tailor/renderer.py:
        ```
"""LaTeX template renderer for resume tailoring."""
from pathlib import Path
import subprocess
from typing import Generator, Union
from .models import LatexTemplateData

class LatexTemplateRenderer:
    """Renders LaTeX templates with provided data."""
    
    def __init__(self, template_path: str | Path):
        self.template_path = Path(template_path)
        if not self.template_path.exists():
            raise FileNotFoundError(f"Template not found at {template_path}")
            
        # Read the template
        with open(self.template_path) as f:
            self.template = f.read()
            
    def render(self, data: LatexTemplateData) -> str:
        """Render the template with the given data."""
        content = self.template
        
        # Contact info
        content = content.replace("{name}", str(data.name))
        content = content.replace("{email}", str(data.email))
        content = content.replace("{phone}", str(data.phone))
        content = content.replace("{linkedin}", str(data.linkedin))
        content = content.replace("{github}", str(data.github))
        
        # Education
        if data.education:
            content = content.replace("{university_name1}", str(data.education[0].university_name))
            content = content.replace("{university_city1}", str(data.education[0].university_city))
            content = content.replace("{university_state1}", str(data.education[0].university_state))
            content = content.replace("{major_degree_name1}", str(data.education[0].major_degree_name))
            content = content.replace("{minor_degree_name1}", str(data.education[0].minor_degree_name or ''))
            content = content.replace("{start_date1}", str(data.education[0].start_date))
            content = content.replace("{end_date1}", str(data.education[0].end_date))
            
        # Experience
        if data.experience:
            # First position
            content = content.replace("{work_title1}", str(data.experience[0].work_title))
            content = content.replace("{work_company1}", str(data.experience[0].work_company))
            content = content.replace("{work_city1}", str(data.experience[0].work_city))
            content = content.replace("{work_state1}", str(data.experience[0].work_state))
            content = content.replace("{work_start_date1}", str(data.experience[0].work_start_date))
            content = content.replace("{work_end_date1}", str(data.experience[0].work_end_date))
            for i, desc in enumerate(data.experience[0].work_descriptions[:3], 1):
                content = content.replace("{work_description_one" + str(i) + "}", str(desc))
                
            # Second position
            if len(data.experience) > 1:
                content = content.replace("{work_title2}", str(data.experience[1].work_title))
                content = content.replace("{work_company2}", str(data.experience[1].work_company))
                content = content.replace("{work_city2}", str(data.experience[1].work_city))
                content = content.replace("{work_state2}", str(data.experience[1].work_state))
                content = content.replace("{work_start_date2}", str(data.experience[1].work_start_date))
                content = content.replace("{work_end_date2}", str(data.experience[1].work_end_date))
                for i, desc in enumerate(data.experience[1].work_descriptions[:3], 1):
                    content = content.replace("{work_description_two" + str(i) + "}", str(desc))
                    
            # Third position
            if len(data.experience) > 2:
                content = content.replace("{work_title3}", str(data.experience[2].work_title))
                content = content.replace("{work_company3}", str(data.experience[2].work_company))
                content = content.replace("{work_city3}", str(data.experience[2].work_city))
                content = content.replace("{work_state3}", str(data.experience[2].work_state))
                content = content.replace("{work_start_date3}", str(data.experience[2].work_start_date))
                content = content.replace("{work_end_date3}", str(data.experience[2].work_end_date))
                for i, desc in enumerate(data.experience[2].work_descriptions[:6], 1):
                    content = content.replace("{work_description_three" + str(i) + "}", str(desc))
                    
        # Projects
        if data.projects:
            # First project
            content = content.replace("{project_1_name}", str(data.projects[0].project_name))
            content = content.replace("{project_1_technologies}", str(data.projects[0].project_technologies))
            content = content.replace("{project1_start_date}", str(data.projects[0].project_start_date))
            content = content.replace("{project1_end_date}", str(data.projects[0].project_end_date))
            for i, bullet in enumerate(data.projects[0].project_bullets[:4], 1):
                content = content.replace("{p1_bullet" + str(i) + "}", str(bullet))
                
            # Second project
            if len(data.projects) > 1:
                content = content.replace("{project_2_name}", str(data.projects[1].project_name))
                content = content.replace("{project_2_technologies}", str(data.projects[1].project_technologies))
                content = content.replace("{project2_start_date}", str(data.projects[1].project_start_date))
                content = content.replace("{project2_end_date}", str(data.projects[1].project_end_date))
                for i, bullet in enumerate(data.projects[1].project_bullets[:4], 1):
                    content = content.replace("{p2_bullet" + str(i) + "}", str(bullet))
                    
        # Technical Skills
        if data.technical_skills:
            content = content.replace("{language_names}", str(data.technical_skills.languages))
            content = content.replace("{framework_names}", str(data.technical_skills.frameworks))
            content = content.replace("{dev_tools_names}", str(data.technical_skills.dev_tools))
            content = content.replace("{library_names}", str(data.technical_skills.libraries))
            
        return content
        
    def render_to_pdf(self, data: LatexTemplateData, output_dir: str | Path, filename: str) -> Generator[str, None, Path]:
        """Render template to PDF with progress updates."""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Create tex file
        tex_path = output_dir / f"{filename}.tex"
        filled_template = self.render(data)
        
        yield "Generated LaTeX content...\n"
        
        with open(tex_path, 'w') as f:
            f.write(filled_template)
            
        yield "Saved LaTeX file...\n"
            
        # Compile to PDF
        try:
            yield "Compiling PDF...\n"
            result = subprocess.run(
                ['pdflatex', '-interaction=nonstopmode', tex_path.name],
                cwd=output_dir,
                capture_output=True,
                text=True,
                check=True
            )
            yield "LaTeX compilation output:\n"
            yield result.stdout + "\n"
            
            pdf_path = output_dir / f"{filename}.pdf"
            if not pdf_path.exists():
                yield "LaTeX error output:\n"
                yield result.stderr + "\n"
                raise RuntimeError("PDF compilation failed")
                
            yield "PDF generated successfully!\n"
            return pdf_path
            
        except subprocess.CalledProcessError as e:
            yield "LaTeX error output:\n"
            yield e.stdout + "\n"
            yield e.stderr + "\n"
            raise 
        ```

        resume_wizard/resume_tailor/test_tailor.py:
        ```
"""Test script for resume tailoring functionality."""
import os
from pathlib import Path
from dotenv import load_dotenv

from resume_wizard.pdf_parsers import parse_single_pdf
from resume_wizard.resume_tailor import tailor_and_render_resume

# Load environment variables
load_dotenv()

# Get API key
api_key = os.getenv("ANTHROPIC_API_KEY")
if not api_key:
    raise ValueError("ANTHROPIC_API_KEY environment variable not set")

# Job description for testing
JOB_DESCRIPTION = """
Jr. Software Development Engineer (SDE) - Amazon
Location: Arlington, VA (In-Person)

Job Description:
We are seeking a talented Jr. Software Development Engineer to join our team at Amazon. As a Jr. SDE, you will work on challenging problems, learn from experienced engineers, and contribute to building scalable software solutions.

Basic Qualifications:
- Currently enrolled in a Bachelor's or Master's degree program in Computer Science, Software Engineering, or related field
- Programming experience with at least one modern language such as Java, Python, C++, or JavaScript
- Understanding of computer science fundamentals including data structures, algorithms, and object-oriented programming
- Ability to work effectively in an Agile team environment
- Strong problem-solving skills and attention to detail

Preferred Qualifications:
- Experience with web services and RESTful APIs
- Familiarity with cloud platforms (AWS, Azure, or GCP)
- Knowledge of version control systems (Git)
- Experience with testing frameworks and CI/CD pipelines
- Strong communication and collaboration skills

Additional Requirements:
- Must be able to work in-person in Arlington, VA
- Willingness to learn and adapt to new technologies
- Passion for building customer-focused solutions

Amazon is an Equal Opportunity Employer
"""

def main():
    """Run the test script."""
    # Load resume - just use filename since get_absolute_path_to_resume handles the directory
    resume_text = parse_single_pdf("spencer-presley-resume.pdf")
    
    # Set up output path
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "tailored_resume.pdf"
    
    # Tailor and render resume
    tailor_and_render_resume(
        resume_text=resume_text,
        job_description=JOB_DESCRIPTION,
        template_data=None,  # Let Claude analyze the resume
        api_key=api_key,
        output_dir=output_dir,
        output_filename=output_file.name
    )
    
    print(f"Tailored resume saved to: {output_file}")

if __name__ == "__main__":
    main() 
        ```

        resume_wizard/resume_tailor/tools.py:
        ```
"""Tools for updating resume template data."""
from typing import Dict, Any, List
from pydantic import BaseModel, Field

class UpdateContactInfo(BaseModel):
    """Tool for updating contact information."""
    name: str = Field(description="Full name")
    email: str = Field(description="Email address")
    phone: str = Field(description="Phone number")
    linkedin: str = Field(description="LinkedIn URL")
    github: str = Field(description="GitHub URL")

class EducationEntry(BaseModel):
    """Model for education entries."""
    university: str = Field(description="University name")
    degree: str = Field(description="Degree name")
    major: str = Field(description="Major/field of study")
    gpa: float = Field(description="GPA (optional)", default=None)
    start_date: str = Field(description="Start date (MM/YYYY)")
    end_date: str = Field(description="End date (MM/YYYY or 'Present')")
    location: str = Field(description="Location (City, State)")

class UpdateEducation(BaseModel):
    """Tool for updating education section."""
    education: List[EducationEntry] = Field(description="List of education entries")

class ExperienceEntry(BaseModel):
    """Model for experience entries."""
    company: str = Field(description="Company name")
    title: str = Field(description="Job title")
    start_date: str = Field(description="Start date (MM/YYYY)")
    end_date: str = Field(description="End date (MM/YYYY or 'Present')")
    location: str = Field(description="Location (City, State)")
    bullets: List[str] = Field(description="List of bullet points describing achievements")

class UpdateExperience(BaseModel):
    """Tool for updating experience section."""
    experience: List[ExperienceEntry] = Field(description="List of experience entries")

class ProjectEntry(BaseModel):
    """Model for project entries."""
    name: str = Field(description="Project name")
    description: str = Field(description="Brief project description")
    technologies: List[str] = Field(description="List of technologies used")
    bullets: List[str] = Field(description="List of bullet points describing achievements")
    url: str = Field(description="Project URL (optional)", default=None)

class UpdateProjects(BaseModel):
    """Tool for updating projects section."""
    projects: List[ProjectEntry] = Field(description="List of project entries")

class UpdateSkills(BaseModel):
    """Tool for updating technical skills."""
    skills: Dict[str, List[str]] = Field(description="Dictionary mapping skill categories to lists of skills")

def create_tailoring_tools() -> List[Dict[str, Any]]:
    """Create tools for updating resume template data.
    
    Returns:
        List[Dict[str, Any]]: List of tool definitions
    """
    return [
        {
            "type": "function",
            "function": {
                "name": "update_contact_info",
                "description": "Update contact information in the template",
                "parameters": UpdateContactInfo.model_json_schema()
            }
        },
        {
            "type": "function",
            "function": {
                "name": "update_education",
                "description": "Update education section in the template",
                "parameters": UpdateEducation.model_json_schema()
            }
        },
        {
            "type": "function",
            "function": {
                "name": "update_experience",
                "description": "Update experience section in the template",
                "parameters": UpdateExperience.model_json_schema()
            }
        },
        {
            "type": "function",
            "function": {
                "name": "update_projects",
                "description": "Update projects section in the template",
                "parameters": UpdateProjects.model_json_schema()
            }
        },
        {
            "type": "function",
            "function": {
                "name": "update_skills",
                "description": "Update technical skills in the template",
                "parameters": UpdateSkills.model_json_schema()
            }
        }
    ] 
        ```

        resume_wizard/tests/test_contact_info_chain.py:
        ```
from __future__ import annotations

import os
import json
from typing import TYPE_CHECKING
from dotenv import load_dotenv
from langchain_anthropic.chat_models import ChatAnthropic
from resume_wizard.ai.chains.contact_info.chain import extract_contact_info, create_contact_info_chain
from resume_wizard.ai.chains.objective.chain import extract_objective, create_objective_chain
from resume_wizard.ai.chains.skills.chain import extract_skills, create_skills_chain
from resume_wizard.ai.chains.education.chain import extract_education, create_education_chain
from resume_wizard.ai.chains.experience.chain import extract_experience, create_experience_chain
from resume_wizard.ai.chains.projects.chain import extract_projects, create_projects_chain
from resume_wizard.pdf_parsers import parse_single_pdf
from resume_wizard.ai.tools import _ResumeParsingTools, _ResumeParserHelper

if TYPE_CHECKING:
    from langchain.docstore.document import Document

document: Document = parse_single_pdf("spencer-presley-resume.pdf")[0]

load_dotenv()

# Create the helper and tools
helper = _ResumeParserHelper()
tools = _ResumeParsingTools(parser_helper=helper)

# First extract contact info
contact_chain = create_contact_info_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Contact Info ===\n")
conversation = extract_contact_info(contact_chain, document.page_content, tools)
print("\nContact Info Conversation:\n")
print(conversation)

# Then extract objective using the same tools instance
objective_chain = create_objective_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Objective ===\n")
conversation = extract_objective(objective_chain, document.page_content, tools)
print("\nObjective Conversation:\n")
print(conversation)

# Then extract all skills
skills_chain = create_skills_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Skills ===\n")
conversation = extract_skills(skills_chain, document.page_content, tools)
print("\nSkills Conversation:\n")
print(conversation)

# Then extract education information
education_chain = create_education_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Education ===\n")
conversation = extract_education(education_chain, document.page_content, tools)
print("\nEducation Conversation:\n")
print(conversation)

# Then extract experience information
experience_chain = create_experience_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Experience ===\n")
conversation = extract_experience(experience_chain, document.page_content, tools)
print("\nExperience Conversation:\n")
print(conversation)

# Finally extract project information
projects_chain = create_projects_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

print("\n=== Extracting Projects ===\n")
conversation = extract_projects(projects_chain, document.page_content, tools)
print("\nProjects Conversation:\n")
print(conversation)

# Build and print the final resume schema with all pieces
print("\nFinal Resume Schema:\n")
resume = tools.build_resume()
print(json.dumps(resume.model_dump(), indent=2))
        ```

        resume_wizard/tests/test_objective_chain.py:
        ```
from __future__ import annotations

import os
import json
from typing import TYPE_CHECKING
from dotenv import load_dotenv
from langchain_anthropic.chat_models import ChatAnthropic
from resume_wizard.ai.chains.objective.chain import extract_objective
from resume_wizard.pdf_parsers import parse_single_pdf
from resume_wizard.ai import create_objective_chain
from resume_wizard.ai.tools import _ResumeParsingTools, _ResumeParserHelper

if TYPE_CHECKING:
    from langchain.docstore.document import Document

document: Document = parse_single_pdf("spencer-presley-resume.pdf")[0]

load_dotenv()

# Create the helper and tools
helper = _ResumeParserHelper()
tools = _ResumeParsingTools(parser_helper=helper)

chain = create_objective_chain(
    os.getenv("ANTHROPIC_API_KEY"),
    tools
)

conversation = extract_objective(chain, document.page_content, tools)
print("\nFull Conversation:\n")
print(conversation)

# Build and print the final resume schema
print("\nFinal Resume Schema:\n")
resume = tools.build_resume()
print(json.dumps(resume.model_dump(), indent=2)) 
        ```

        resume_wizard/vectordb/__init__.py:
        ```
from .manager import VectorDBManager
from .searcher import VectorDBSearcher

__all__ = ["VectorDBManager", "VectorDBSearcher"]

        ```

        resume_wizard/vectordb/manager.py:
        ```
import os
import json
from dotenv import load_dotenv
from typing import Dict, Any, List
from pathlib import Path

from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
import faiss
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS

from resume_wizard.globals import RESUMES_DIR
from resume_wizard.wizard import run_resume_wizard

# Add vector db directory constant
VECTOR_DB_DIR = Path(__file__).parent / "vector_db"
VECTOR_DB_NAME = "resume_db"

load_dotenv()

class VectorDBManager:
    def __init__(
        self,
        api_key: str,
        index_type: str | None = "HNSW"
    ):
        self._embeddings = OpenAIEmbeddings(api_key=api_key)
        self._embedding_size = len(self._embeddings.embed_query("test"))
        self._index = self._create_index(index_type)
        self._raw_data = self._get_raw_resume_data()
        self.db = None
        
        # Create vector db directory if it doesn't exist
        VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)
        
    @classmethod
    def load_existing(cls, api_key: str) -> 'VectorDBManager':
        """Load an existing VectorDBManager with a pre-existing database."""
        manager = cls(api_key)
        try:
            manager.db = FAISS.load_local(
                folder_path=str(VECTOR_DB_DIR),
                index_name=VECTOR_DB_NAME,
                embeddings=manager._embeddings,
                allow_dangerous_deserialization=True  # Safe because we're loading our own files
            )
        except Exception as e:
            print(f"Warning: Could not load existing database: {e}")
            # Create a new database if loading fails
            manager.db = manager.create_db().get_db()
        return manager

    def add_single_resume(self, pdf_filename: str) -> bool:
        """Process and add a single resume to the existing vector database.
        
        Args:
            pdf_filename: The name of the PDF file to process
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            if not self.db:
                # Try to load existing database
                self.db = FAISS.load_local(
                    folder_path=str(VECTOR_DB_DIR),
                    index_name=VECTOR_DB_NAME,
                    embeddings=self._embeddings,
                    allow_dangerous_deserialization=True  # Safe because we're loading our own files
                )
            
            # Process the single resume and get the final data
            resume_generator = run_resume_wizard(pdf_filename, stream=True)
            resume_data = None
            
            # Stream all updates and capture the final JSON string
            for item in resume_generator:
                if isinstance(item, str) and item.startswith('{'): # Capture the JSON string
                    resume_data = json.loads(item)
                yield item  # Stream everything to the frontend
            
            if not resume_data:
                raise ValueError("No resume data generated")
                
            documents = self._process_resume_data(resume_data, pdf_filename)
            
            # Add to database
            self.db.add_documents(documents)
            
            # Save the updated database
            self.db.save_local(str(VECTOR_DB_DIR), VECTOR_DB_NAME)
            
            return True
            
        except Exception as e:
            print(f"Error adding resume to database: {e}")
            return False
        
    def create_db(self) -> FAISS:
        try:
            self.db = FAISS(
                embedding_function=self._embeddings,
                index=self._index,
                docstore=InMemoryDocstore(),
                index_to_docstore_id={}
            )
            return self
        except Exception as e:
            print(f"Error creating FAISS database: {e}")
            return None
        
    def add_docs_to_db(self) -> None:
        if not self.db:
            raise ValueError("Database not created. Call create_db() first.")
        
        for pdf_file, resume_data in zip(os.listdir(RESUMES_DIR), self._raw_data):
            documents = self._process_resume_data(resume_data, pdf_file)
            self.db.add_documents(documents)
        
        return self
    
    def get_db(self) -> FAISS:
        return self.db
        
    def _create_index(self, index_type: str) -> faiss.Index:
        if index_type == "HNSW":
            try:
                return faiss.IndexHNSWFlat(self._embedding_size, 32)
            except Exception as e:
                print(f"Error creating HNSW index: {e}")
                return faiss.IndexFlatL2(self._embedding_size)
        else:
            try:
                return faiss.IndexFlatL2(self._embedding_size)
            except Exception as e:
                print(f"Error creating Flat index: {e}")
                return faiss.IndexFlatL2(self._embedding_size)
        
    def _get_raw_resume_data(self) -> list[dict]:
        resume_pdfs = os.listdir(RESUMES_DIR)
        data: list[dict] = []
        for pdf in resume_pdfs:
            resume_data = run_resume_wizard(pdf)
            data.append(resume_data)
        return data
        
    def _process_resume_data(self, resume_data: Dict[str, Any], pdf_file: str) -> List[Document]:
        """Process resume data into documents for vector storage.
        
        Args:
            resume_data: The parsed resume data
            pdf_file: The name of the PDF file
            
        Returns:
            List[Document]: List of documents ready for vector storage
        """
        documents = []
        
        # Convert skills dict to string representation
        skills_str = "Skills:\n"
        skills_data = resume_data.get("skills", {})
        for category, skills in skills_data.items():
            if skills:  # Only add category if it has skills
                skills_str += f"{category.title()}: {', '.join(skills)}\n"
        
        # Add skills document if we have skills
        if skills_str != "Skills:\n":
            documents.append(Document(
                page_content=skills_str,
                metadata={
                    "source": pdf_file,
                    "section": "skills"
                }
            ))
        
        # Add objective document if it exists
        objective = resume_data.get("objective")
        if objective:
            documents.append(Document(
                page_content=str(objective),
                metadata={
                    "source": pdf_file,
                    "section": "objective"
                }
            ))
        
        # Add experience documents
        for exp in resume_data.get("experience", []):
            if exp.get("position") and exp.get("company"):
                content = f"{exp.get('position')} at {exp.get('company')}"
                if exp.get("description"):
                    content += f"\n{exp.get('description')}"
                    
                documents.append(Document(
                    page_content=content,
                    metadata={
                        "source": pdf_file,
                        "section": "experience",
                        "position": exp.get("position"),
                        "company": exp.get("company")
                    }
                ))
        
        # Add project documents
        for proj in resume_data.get("projects", []):
            if proj.get("name"):
                content = proj.get("name", "")
                if proj.get("description"):
                    content += f"\n{proj.get('description')}"
                    
                documents.append(Document(
                    page_content=content,
                    metadata={
                        "source": pdf_file,
                        "section": "projects",
                        "name": proj.get("name")
                    }
                ))
        
        return documents
    
if __name__ == "__main__":
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    vdb_manager = VectorDBManager(openai_api_key)
    vdb = vdb_manager.create_db().add_docs_to_db().get_db()
    vdb.save_local(str(VECTOR_DB_DIR), VECTOR_DB_NAME)

        ```

        resume_wizard/vectordb/searcher.py:
        ```
from __future__ import annotations

import os
from typing import Optional, TYPE_CHECKING, List, Dict, Union
from enum import Enum

if TYPE_CHECKING:
    from pathlib import Path

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

class ResumeSection(Enum):
    BASIC_INFO = "basic_info"
    OBJECTIVE = "objective"
    EDUCATION = "education"
    EXPERIENCE = "experience"
    SKILLS = "skills"
    PROJECTS = "projects"

class VectorDBSearcher:
    def __init__(
        self, 
        vector_db_dir: Path, 
        database_name: str, 
        embeddings: OpenAIEmbeddings
    ):
        self.vector_db_dir = vector_db_dir
        self.database_name = database_name
        self.embeddings = embeddings

        # Enhanced metadata schema for resumes
        self.metadata_schema = {
            "section": [section.value for section in ResumeSection],
            "source": [],  # Will be populated with resume filenames
            "name": [],    # Will be populated with candidate names
            "email": [],   # Will be populated with candidate emails
        }
        self.database = self.load_database()

    def load_database(self) -> FAISS:
        """Load the FAISS database and attach metadata schema."""
        try:
            db = FAISS.load_local(
                folder_path=str(self.vector_db_dir),
                index_name=self.database_name,
                embeddings=self.embeddings,
                allow_dangerous_deserialization=True,
            )
            # Attach metadata schema to loaded database
            db.metadata_schema = self.metadata_schema
            return db
        except Exception as e:
            raise RuntimeError(f"Failed to load database: {e}")

    def get_relevant_candidates(
        self,
        prompt: str,
        *,
        section: Optional[Union[ResumeSection, str]] = None, # filter by section
        source_file: Optional[str] = None, # filter by source file
        candidate_name: Optional[str] = None, # filter by candidate name
        candidate_email: Optional[str] = None, # filter by candidate email
        max_docs: int = 5, # number of candidates to return
        score_threshold: float = 0.5, # minimum relevance score
    ) -> List[Dict]:
        """Enhanced search with multiple filtering options.

        Args:
            prompt: Search query
            section: Specific resume section to search in
            source_file: Specific resume file to search in
            candidate_name: Search by candidate name
            candidate_email: Search by candidate email
            max_docs: Maximum number of documents to return
            score_threshold: Minimum relevance score (0-1)

        Returns:
            List[Dict]: List of relevant documents with their metadata
        """
        try:
            metadata_filter = {}

            # Add section filter if specified
            if section:
                section_value = section.value if isinstance(section, ResumeSection) else section
                metadata_filter["section"] = section_value

            # Add other filters if specified
            if source_file:
                metadata_filter["source"] = source_file
            if candidate_name:
                metadata_filter["name"] = candidate_name
            if candidate_email:
                metadata_filter["email"] = candidate_email

            # Perform search with filters
            docs_and_scores = self.database.similarity_search_with_relevance_scores(
                prompt,
                k=max_docs,
                filter=metadata_filter if metadata_filter else None
            )

            # Format results with metadata
            results = []
            for doc, score in docs_and_scores:
                if score >= score_threshold:
                    results.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "relevance_score": score
                    })

            return results[:max_docs]

        except Exception as e:
            print(f"Warning: Failed to retrieve relevant documents: {e}")
            return []

    def search_by_section(
        self,
        section: ResumeSection, # specifically get candidates from this section
        prompt: str,
        max_docs: int = 3
    ) -> List[Dict]:
        """Convenience method to search within a specific section"""
        return self.get_relevant_docs(
            prompt=prompt,
            section=section,
            max_docs=max_docs
        )

    def search_by_candidate( # search by candidate name or email
        self,
        prompt: str,
        *,
        name: Optional[str] = None,
        email: Optional[str] = None,
        max_docs: int = 3
    ) -> List[Dict]:
        """Convenience method to search by candidate info"""
        return self.get_relevant_docs(
            prompt=prompt,
            candidate_name=name,
            candidate_email=email,
            max_docs=max_docs
        )
        ```

        resume_wizard/wizard/__init__.py:
        ```
from .rezwiz import run_resume_wizard

__all__ = ["run_resume_wizard"]
        ```

        resume_wizard/wizard/rezwiz.py:
        ```
from __future__ import annotations

import os
import json
from typing import TYPE_CHECKING, Generator, Dict, Any
from dotenv import load_dotenv
from langchain_anthropic.chat_models import ChatAnthropic
from resume_wizard.ai.chains.contact_info.chain import extract_contact_info, create_contact_info_chain
from resume_wizard.ai.chains.objective.chain import extract_objective, create_objective_chain
from resume_wizard.ai.chains.skills.chain import extract_skills, create_skills_chain
from resume_wizard.ai.chains.education.chain import extract_education, create_education_chain
from resume_wizard.ai.chains.experience.chain import extract_experience, create_experience_chain
from resume_wizard.ai.chains.projects.chain import extract_projects, create_projects_chain
from resume_wizard.pdf_parsers import parse_single_pdf
from resume_wizard.ai.tools import _ResumeParsingTools, _ResumeParserHelper
import sys
from io import StringIO
from contextlib import contextmanager

if TYPE_CHECKING:
    from langchain.docstore.document import Document

# Rebuild the model at module level
_ResumeParsingTools.model_rebuild()

def format_conversation(conversation: str) -> str:
    """Format the conversation to be more readable."""
    lines = conversation.split('\n')
    formatted_lines = []
    for line in lines:
        if line.startswith('Human:'):
            formatted_lines.append('\n🧑 User:')
            formatted_lines.append('  ' + line[7:].strip())
        elif line.startswith('Assistant:'):
            formatted_lines.append('\n🤖 Claude:')
            formatted_lines.append('  ' + line[11:].strip())
        elif line.startswith('Tool'):
            formatted_lines.append('\n🛠️ Tool Output:')
            formatted_lines.append('  ' + line[line.find(':')+1:].strip())
        elif line.strip():
            formatted_lines.append('  ' + line.strip())
    return '\n'.join(formatted_lines)

@contextmanager
def capture_output():
    """Capture stdout and stderr"""
    new_out, new_err = StringIO(), StringIO()
    old_out, old_err = sys.stdout, sys.stderr
    try:
        sys.stdout, sys.stderr = new_out, new_err
        yield sys.stdout, sys.stderr
    finally:
        sys.stdout, sys.stderr = old_out, old_err

def run_resume_wizard(resume_file_name: str, stream: bool = False) -> dict | Generator[str, None, None]:
    """Run the resume wizard on a PDF file.
    
    Args:
        resume_file_name: Name of the PDF file to process
        stream: If True, yield status updates as they happen
        
    Returns:
        If stream=False: The processed resume data as a dict
        If stream=True: A generator yielding status updates
    """
    document: Document = parse_single_pdf(resume_file_name)[0]
    load_dotenv()

    # Create helper and tools
    helper = _ResumeParserHelper()
    tools = _ResumeParsingTools(parser_helper=helper)

    sections = [
        ("Contact Info", create_contact_info_chain, extract_contact_info),
        ("Objective", create_objective_chain, extract_objective),
        ("Skills", create_skills_chain, extract_skills),
        ("Education", create_education_chain, extract_education),
        ("Experience", create_experience_chain, extract_experience),
        ("Projects", create_projects_chain, extract_projects)
    ]

    for section_name, create_chain, extract_func in sections:
        status = f"\n{'='*20} Processing {section_name} {'='*20}\n"
        if stream:
            yield status
        else:
            print(status)

        # Capture all output during chain creation and execution
        with capture_output() as (out, err):
            chain = create_chain(os.getenv("ANTHROPIC_API_KEY"), tools)
            conversation = extract_func(chain, document.page_content, tools)
            
            # Get any output that was captured
            stdout = out.getvalue()
            stderr = err.getvalue()
            
            if stream and (stdout or stderr):
                yield stdout
                if stderr:
                    yield stderr

        formatted = format_conversation(conversation)
        if stream:
            yield formatted + "\n"
        else:
            print(formatted)

    # Build the final resume schema
    with capture_output() as (out, err):
        resume_data = tools.build_resume()
        stdout = out.getvalue()
        stderr = err.getvalue()
        
        if stream and (stdout or stderr):
            yield stdout
            if stderr:
                yield stderr

    final_status = "\n✨ Final Resume Data:\n"
    if stream:
        yield final_status
        yield json.dumps(resume_data.model_dump(), indent=2)
    else:
        print(final_status)
        print(json.dumps(resume_data.model_dump(), indent=2))

    if not stream:
        return resume_data.model_dump()
        ```
